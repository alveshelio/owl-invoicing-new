# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
  "refresh the cache entry"
  refresh: Boolean! = false,
  "measured in seconds"
  ttl: Int! = 60
) on QUERY

"columns and relationships of \"InvoiceQuotationCategories\""
type InvoiceQuotationCategories {
  "An array relationship"
  InvoiceSections(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "An aggregate relationship"
  InvoiceSections_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): InvoiceSections_aggregate!
  "An object relationship"
  Organization: Organizations
  "An array relationship"
  QuotationSections(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "An aggregate relationship"
  QuotationSections_aggregate(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): QuotationSections_aggregate!
  created_at: timestamptz!
  id: uuid!
  organizationId: uuid!
  updated_at: timestamptz!
  value: String!
}

"aggregated selection of \"InvoiceQuotationCategories\""
type InvoiceQuotationCategories_aggregate {
  aggregate: InvoiceQuotationCategories_aggregate_fields
  nodes: [InvoiceQuotationCategories!]!
}

"aggregate fields of \"InvoiceQuotationCategories\""
type InvoiceQuotationCategories_aggregate_fields {
  count(columns: [InvoiceQuotationCategories_select_column!], distinct: Boolean): Int!
  max: InvoiceQuotationCategories_max_fields
  min: InvoiceQuotationCategories_min_fields
}

"aggregate max on columns"
type InvoiceQuotationCategories_max_fields {
  created_at: timestamptz
  id: uuid
  organizationId: uuid
  updated_at: timestamptz
  value: String
}

"aggregate min on columns"
type InvoiceQuotationCategories_min_fields {
  created_at: timestamptz
  id: uuid
  organizationId: uuid
  updated_at: timestamptz
  value: String
}

"response of any mutation on the table \"InvoiceQuotationCategories\""
type InvoiceQuotationCategories_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [InvoiceQuotationCategories!]!
}

"columns and relationships of \"InvoiceSectionItems\""
type InvoiceSectionItems {
  "An object relationship"
  InvoiceSection: InvoiceSections!
  "An object relationship"
  Organization: Organizations
  createdAt: timestamptz!
  description: String
  id: uuid!
  name: String!
  organizationId: uuid!
  price: numeric!
  quantity: Int!
  sectionId: uuid!
  updatedAt: timestamptz!
}

"aggregated selection of \"InvoiceSectionItems\""
type InvoiceSectionItems_aggregate {
  aggregate: InvoiceSectionItems_aggregate_fields
  nodes: [InvoiceSectionItems!]!
}

"aggregate fields of \"InvoiceSectionItems\""
type InvoiceSectionItems_aggregate_fields {
  avg: InvoiceSectionItems_avg_fields
  count(columns: [InvoiceSectionItems_select_column!], distinct: Boolean): Int!
  max: InvoiceSectionItems_max_fields
  min: InvoiceSectionItems_min_fields
  stddev: InvoiceSectionItems_stddev_fields
  stddev_pop: InvoiceSectionItems_stddev_pop_fields
  stddev_samp: InvoiceSectionItems_stddev_samp_fields
  sum: InvoiceSectionItems_sum_fields
  var_pop: InvoiceSectionItems_var_pop_fields
  var_samp: InvoiceSectionItems_var_samp_fields
  variance: InvoiceSectionItems_variance_fields
}

"aggregate avg on columns"
type InvoiceSectionItems_avg_fields {
  price: Float
  quantity: Float
}

"aggregate max on columns"
type InvoiceSectionItems_max_fields {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"aggregate min on columns"
type InvoiceSectionItems_min_fields {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"response of any mutation on the table \"InvoiceSectionItems\""
type InvoiceSectionItems_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [InvoiceSectionItems!]!
}

"aggregate stddev on columns"
type InvoiceSectionItems_stddev_fields {
  price: Float
  quantity: Float
}

"aggregate stddev_pop on columns"
type InvoiceSectionItems_stddev_pop_fields {
  price: Float
  quantity: Float
}

"aggregate stddev_samp on columns"
type InvoiceSectionItems_stddev_samp_fields {
  price: Float
  quantity: Float
}

"aggregate sum on columns"
type InvoiceSectionItems_sum_fields {
  price: numeric
  quantity: Int
}

"aggregate var_pop on columns"
type InvoiceSectionItems_var_pop_fields {
  price: Float
  quantity: Float
}

"aggregate var_samp on columns"
type InvoiceSectionItems_var_samp_fields {
  price: Float
  quantity: Float
}

"aggregate variance on columns"
type InvoiceSectionItems_variance_fields {
  price: Float
  quantity: Float
}

"columns and relationships of \"InvoiceSections\""
type InvoiceSections {
  "An object relationship"
  Category: InvoiceQuotationCategories
  "An object relationship"
  Invoice: Invoices!
  "An array relationship"
  InvoiceSectionItems(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): [InvoiceSectionItems!]!
  "An aggregate relationship"
  InvoiceSectionItems_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): InvoiceSectionItems_aggregate!
  "An object relationship"
  Organization: Organizations
  "An object relationship"
  Unit: Units!
  categoryId: uuid!
  createdAt: timestamptz!
  id: uuid!
  invoiceId: uuid!
  name: bpchar!
  organizationId: uuid!
  unit: String!
  updatedAt: timestamptz!
}

"aggregated selection of \"InvoiceSections\""
type InvoiceSections_aggregate {
  aggregate: InvoiceSections_aggregate_fields
  nodes: [InvoiceSections!]!
}

"aggregate fields of \"InvoiceSections\""
type InvoiceSections_aggregate_fields {
  count(columns: [InvoiceSections_select_column!], distinct: Boolean): Int!
  max: InvoiceSections_max_fields
  min: InvoiceSections_min_fields
}

"aggregate max on columns"
type InvoiceSections_max_fields {
  categoryId: uuid
  createdAt: timestamptz
  id: uuid
  invoiceId: uuid
  name: bpchar
  organizationId: uuid
  unit: String
  updatedAt: timestamptz
}

"aggregate min on columns"
type InvoiceSections_min_fields {
  categoryId: uuid
  createdAt: timestamptz
  id: uuid
  invoiceId: uuid
  name: bpchar
  organizationId: uuid
  unit: String
  updatedAt: timestamptz
}

"response of any mutation on the table \"InvoiceSections\""
type InvoiceSections_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [InvoiceSections!]!
}

"columns and relationships of \"InvoiceStatuses\""
type InvoiceStatuses {
  "An array relationship"
  Invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "An aggregate relationship"
  Invoices_aggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  value: String!
}

"aggregated selection of \"InvoiceStatuses\""
type InvoiceStatuses_aggregate {
  aggregate: InvoiceStatuses_aggregate_fields
  nodes: [InvoiceStatuses!]!
}

"aggregate fields of \"InvoiceStatuses\""
type InvoiceStatuses_aggregate_fields {
  count(columns: [InvoiceStatuses_select_column!], distinct: Boolean): Int!
  max: InvoiceStatuses_max_fields
  min: InvoiceStatuses_min_fields
}

"aggregate max on columns"
type InvoiceStatuses_max_fields {
  value: String
}

"aggregate min on columns"
type InvoiceStatuses_min_fields {
  value: String
}

"response of any mutation on the table \"InvoiceStatuses\""
type InvoiceStatuses_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [InvoiceStatuses!]!
}

"columns and relationships of \"Invoices\""
type Invoices {
  "An object relationship"
  Client: OrganizationClients
  "An array relationship"
  InvoiceSections(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "An aggregate relationship"
  InvoiceSections_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): InvoiceSections_aggregate!
  "An object relationship"
  InvoiceStatus: InvoiceStatuses!
  "An object relationship"
  Organization: Organizations!
  "An object relationship"
  Quotation: Quotations
  amount: numeric!
  clientId: uuid!
  createdAt: timestamptz!
  dueOn: date!
  id: uuid!
  number: Int!
  organizationId: uuid!
  quotationId: uuid
  sent: Boolean!
  status: String!
  updatedAt: timestamptz!
  viewed: Boolean!
}

"aggregated selection of \"Invoices\""
type Invoices_aggregate {
  aggregate: Invoices_aggregate_fields
  nodes: [Invoices!]!
}

"aggregate fields of \"Invoices\""
type Invoices_aggregate_fields {
  avg: Invoices_avg_fields
  count(columns: [Invoices_select_column!], distinct: Boolean): Int!
  max: Invoices_max_fields
  min: Invoices_min_fields
  stddev: Invoices_stddev_fields
  stddev_pop: Invoices_stddev_pop_fields
  stddev_samp: Invoices_stddev_samp_fields
  sum: Invoices_sum_fields
  var_pop: Invoices_var_pop_fields
  var_samp: Invoices_var_samp_fields
  variance: Invoices_variance_fields
}

"aggregate avg on columns"
type Invoices_avg_fields {
  amount: Float
  number: Float
}

"aggregate max on columns"
type Invoices_max_fields {
  amount: numeric
  clientId: uuid
  createdAt: timestamptz
  dueOn: date
  id: uuid
  number: Int
  organizationId: uuid
  quotationId: uuid
  status: String
  updatedAt: timestamptz
}

"aggregate min on columns"
type Invoices_min_fields {
  amount: numeric
  clientId: uuid
  createdAt: timestamptz
  dueOn: date
  id: uuid
  number: Int
  organizationId: uuid
  quotationId: uuid
  status: String
  updatedAt: timestamptz
}

"response of any mutation on the table \"Invoices\""
type Invoices_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Invoices!]!
}

"aggregate stddev on columns"
type Invoices_stddev_fields {
  amount: Float
  number: Float
}

"aggregate stddev_pop on columns"
type Invoices_stddev_pop_fields {
  amount: Float
  number: Float
}

"aggregate stddev_samp on columns"
type Invoices_stddev_samp_fields {
  amount: Float
  number: Float
}

"aggregate sum on columns"
type Invoices_sum_fields {
  amount: numeric
  number: Int
}

"aggregate var_pop on columns"
type Invoices_var_pop_fields {
  amount: Float
  number: Float
}

"aggregate var_samp on columns"
type Invoices_var_samp_fields {
  amount: Float
  number: Float
}

"aggregate variance on columns"
type Invoices_variance_fields {
  amount: Float
  number: Float
}

"columns and relationships of \"OrganizationClients\""
type OrganizationClients {
  "An array relationship"
  Invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "An aggregate relationship"
  Invoices_aggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  "An object relationship"
  Organization: Organizations!
  "An array relationship"
  Quotations(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "An aggregate relationship"
  Quotations_aggregate(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): Quotations_aggregate!
  city: String
  country: String
  createdAt: timestamp!
  email: String!
  id: uuid!
  name: String!
  organizationId: uuid!
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz!
}

"aggregated selection of \"OrganizationClients\""
type OrganizationClients_aggregate {
  aggregate: OrganizationClients_aggregate_fields
  nodes: [OrganizationClients!]!
}

"aggregate fields of \"OrganizationClients\""
type OrganizationClients_aggregate_fields {
  count(columns: [OrganizationClients_select_column!], distinct: Boolean): Int!
  max: OrganizationClients_max_fields
  min: OrganizationClients_min_fields
}

"aggregate max on columns"
type OrganizationClients_max_fields {
  city: String
  country: String
  createdAt: timestamp
  email: String
  id: uuid
  name: String
  organizationId: uuid
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz
}

"aggregate min on columns"
type OrganizationClients_min_fields {
  city: String
  country: String
  createdAt: timestamp
  email: String
  id: uuid
  name: String
  organizationId: uuid
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz
}

"response of any mutation on the table \"OrganizationClients\""
type OrganizationClients_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [OrganizationClients!]!
}

"columns and relationships of \"Organizations\""
type Organizations {
  "An array relationship"
  Clients(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): [OrganizationClients!]!
  "An aggregate relationship"
  Clients_aggregate(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): OrganizationClients_aggregate!
  "An array relationship"
  Invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "An aggregate relationship"
  Invoices_aggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  "An array relationship"
  Quotations(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "An aggregate relationship"
  Quotations_aggregate(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): Quotations_aggregate!
  "An array relationship"
  Stocks(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): [Stocks!]!
  "An aggregate relationship"
  Stocks_aggregate(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): Stocks_aggregate!
  "An object relationship"
  authorizer_user: authorizer_users!
  city: String!
  createdAt: timestamp!
  email: String!
  id: uuid!
  name: bpchar!
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String!
  state: String
  street: String!
  updatedAt: timestamp!
  userId: bpchar!
}

"aggregated selection of \"Organizations\""
type Organizations_aggregate {
  aggregate: Organizations_aggregate_fields
  nodes: [Organizations!]!
}

"aggregate fields of \"Organizations\""
type Organizations_aggregate_fields {
  count(columns: [Organizations_select_column!], distinct: Boolean): Int!
  max: Organizations_max_fields
  min: Organizations_min_fields
}

"aggregate max on columns"
type Organizations_max_fields {
  city: String
  createdAt: timestamp
  email: String
  id: uuid
  name: bpchar
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamp
  userId: bpchar
}

"aggregate min on columns"
type Organizations_min_fields {
  city: String
  createdAt: timestamp
  email: String
  id: uuid
  name: bpchar
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamp
  userId: bpchar
}

"response of any mutation on the table \"Organizations\""
type Organizations_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Organizations!]!
}

"columns and relationships of \"QuotationSectionItems\""
type QuotationSectionItems {
  "An object relationship"
  Organization: Organizations
  "An object relationship"
  QuotationSection: QuotationSections!
  createdAt: timestamptz!
  description: String
  id: uuid!
  name: String!
  organizationId: uuid!
  price: numeric!
  quantity: Int!
  sectionId: uuid!
  updatedAt: timestamptz!
}

"aggregated selection of \"QuotationSectionItems\""
type QuotationSectionItems_aggregate {
  aggregate: QuotationSectionItems_aggregate_fields
  nodes: [QuotationSectionItems!]!
}

"aggregate fields of \"QuotationSectionItems\""
type QuotationSectionItems_aggregate_fields {
  avg: QuotationSectionItems_avg_fields
  count(columns: [QuotationSectionItems_select_column!], distinct: Boolean): Int!
  max: QuotationSectionItems_max_fields
  min: QuotationSectionItems_min_fields
  stddev: QuotationSectionItems_stddev_fields
  stddev_pop: QuotationSectionItems_stddev_pop_fields
  stddev_samp: QuotationSectionItems_stddev_samp_fields
  sum: QuotationSectionItems_sum_fields
  var_pop: QuotationSectionItems_var_pop_fields
  var_samp: QuotationSectionItems_var_samp_fields
  variance: QuotationSectionItems_variance_fields
}

"aggregate avg on columns"
type QuotationSectionItems_avg_fields {
  price: Float
  quantity: Float
}

"aggregate max on columns"
type QuotationSectionItems_max_fields {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"aggregate min on columns"
type QuotationSectionItems_min_fields {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"response of any mutation on the table \"QuotationSectionItems\""
type QuotationSectionItems_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [QuotationSectionItems!]!
}

"aggregate stddev on columns"
type QuotationSectionItems_stddev_fields {
  price: Float
  quantity: Float
}

"aggregate stddev_pop on columns"
type QuotationSectionItems_stddev_pop_fields {
  price: Float
  quantity: Float
}

"aggregate stddev_samp on columns"
type QuotationSectionItems_stddev_samp_fields {
  price: Float
  quantity: Float
}

"aggregate sum on columns"
type QuotationSectionItems_sum_fields {
  price: numeric
  quantity: Int
}

"aggregate var_pop on columns"
type QuotationSectionItems_var_pop_fields {
  price: Float
  quantity: Float
}

"aggregate var_samp on columns"
type QuotationSectionItems_var_samp_fields {
  price: Float
  quantity: Float
}

"aggregate variance on columns"
type QuotationSectionItems_variance_fields {
  price: Float
  quantity: Float
}

"columns and relationships of \"QuotationSections\""
type QuotationSections {
  "An object relationship"
  Category: InvoiceQuotationCategories
  "An object relationship"
  Organization: Organizations
  "An object relationship"
  Quotation: Quotations!
  "An array relationship"
  QuotationSectionItems(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): [QuotationSectionItems!]!
  "An aggregate relationship"
  QuotationSectionItems_aggregate(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): QuotationSectionItems_aggregate!
  "An object relationship"
  Unit: Units!
  categoryId: uuid!
  createdAt: timestamp!
  id: uuid!
  name: String!
  organizationId: uuid!
  quotationId: uuid!
  unit: String!
  updatedAt: timestamptz!
}

"aggregated selection of \"QuotationSections\""
type QuotationSections_aggregate {
  aggregate: QuotationSections_aggregate_fields
  nodes: [QuotationSections!]!
}

"aggregate fields of \"QuotationSections\""
type QuotationSections_aggregate_fields {
  count(columns: [QuotationSections_select_column!], distinct: Boolean): Int!
  max: QuotationSections_max_fields
  min: QuotationSections_min_fields
}

"aggregate max on columns"
type QuotationSections_max_fields {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  quotationId: uuid
  unit: String
  updatedAt: timestamptz
}

"aggregate min on columns"
type QuotationSections_min_fields {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  quotationId: uuid
  unit: String
  updatedAt: timestamptz
}

"response of any mutation on the table \"QuotationSections\""
type QuotationSections_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [QuotationSections!]!
}

"columns and relationships of \"QuotationStatuses\""
type QuotationStatuses {
  "An array relationship"
  Quotations(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "An aggregate relationship"
  Quotations_aggregate(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): Quotations_aggregate!
  value: String!
}

"aggregated selection of \"QuotationStatuses\""
type QuotationStatuses_aggregate {
  aggregate: QuotationStatuses_aggregate_fields
  nodes: [QuotationStatuses!]!
}

"aggregate fields of \"QuotationStatuses\""
type QuotationStatuses_aggregate_fields {
  count(columns: [QuotationStatuses_select_column!], distinct: Boolean): Int!
  max: QuotationStatuses_max_fields
  min: QuotationStatuses_min_fields
}

"aggregate max on columns"
type QuotationStatuses_max_fields {
  value: String
}

"aggregate min on columns"
type QuotationStatuses_min_fields {
  value: String
}

"response of any mutation on the table \"QuotationStatuses\""
type QuotationStatuses_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [QuotationStatuses!]!
}

"columns and relationships of \"Quotations\""
type Quotations {
  "An object relationship"
  Client: OrganizationClients
  "An array relationship"
  Invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "An aggregate relationship"
  Invoices_aggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  "An object relationship"
  Organization: Organizations!
  "An array relationship"
  QuotationSections(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "An aggregate relationship"
  QuotationSections_aggregate(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): QuotationSections_aggregate!
  "An object relationship"
  QuotationStatus: QuotationStatuses!
  clientId: uuid!
  createdAt: timestamp!
  id: uuid!
  number: Int!
  organizationId: uuid!
  sent: Boolean!
  status: String!
  updatedAt: timestamp!
  validUntil: date!
  viewed: Boolean!
}

"aggregated selection of \"Quotations\""
type Quotations_aggregate {
  aggregate: Quotations_aggregate_fields
  nodes: [Quotations!]!
}

"aggregate fields of \"Quotations\""
type Quotations_aggregate_fields {
  avg: Quotations_avg_fields
  count(columns: [Quotations_select_column!], distinct: Boolean): Int!
  max: Quotations_max_fields
  min: Quotations_min_fields
  stddev: Quotations_stddev_fields
  stddev_pop: Quotations_stddev_pop_fields
  stddev_samp: Quotations_stddev_samp_fields
  sum: Quotations_sum_fields
  var_pop: Quotations_var_pop_fields
  var_samp: Quotations_var_samp_fields
  variance: Quotations_variance_fields
}

"aggregate avg on columns"
type Quotations_avg_fields {
  number: Float
}

"aggregate max on columns"
type Quotations_max_fields {
  clientId: uuid
  createdAt: timestamp
  id: uuid
  number: Int
  organizationId: uuid
  status: String
  updatedAt: timestamp
  validUntil: date
}

"aggregate min on columns"
type Quotations_min_fields {
  clientId: uuid
  createdAt: timestamp
  id: uuid
  number: Int
  organizationId: uuid
  status: String
  updatedAt: timestamp
  validUntil: date
}

"response of any mutation on the table \"Quotations\""
type Quotations_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Quotations!]!
}

"aggregate stddev on columns"
type Quotations_stddev_fields {
  number: Float
}

"aggregate stddev_pop on columns"
type Quotations_stddev_pop_fields {
  number: Float
}

"aggregate stddev_samp on columns"
type Quotations_stddev_samp_fields {
  number: Float
}

"aggregate sum on columns"
type Quotations_sum_fields {
  number: Int
}

"aggregate var_pop on columns"
type Quotations_var_pop_fields {
  number: Float
}

"aggregate var_samp on columns"
type Quotations_var_samp_fields {
  number: Float
}

"aggregate variance on columns"
type Quotations_variance_fields {
  number: Float
}

"columns and relationships of \"Roles\""
type Roles {
  value: String!
}

"aggregated selection of \"Roles\""
type Roles_aggregate {
  aggregate: Roles_aggregate_fields
  nodes: [Roles!]!
}

"aggregate fields of \"Roles\""
type Roles_aggregate_fields {
  count(columns: [Roles_select_column!], distinct: Boolean): Int!
  max: Roles_max_fields
  min: Roles_min_fields
}

"aggregate max on columns"
type Roles_max_fields {
  value: String
}

"aggregate min on columns"
type Roles_min_fields {
  value: String
}

"response of any mutation on the table \"Roles\""
type Roles_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Roles!]!
}

"columns and relationships of \"StockCategories\""
type StockCategories {
  "An object relationship"
  Organization: Organizations
  "An array relationship"
  Stocks(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): [Stocks!]!
  "An aggregate relationship"
  Stocks_aggregate(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): Stocks_aggregate!
  id: uuid!
  organizationId: uuid!
  value: String!
}

"aggregated selection of \"StockCategories\""
type StockCategories_aggregate {
  aggregate: StockCategories_aggregate_fields
  nodes: [StockCategories!]!
}

"aggregate fields of \"StockCategories\""
type StockCategories_aggregate_fields {
  count(columns: [StockCategories_select_column!], distinct: Boolean): Int!
  max: StockCategories_max_fields
  min: StockCategories_min_fields
}

"aggregate max on columns"
type StockCategories_max_fields {
  id: uuid
  organizationId: uuid
  value: String
}

"aggregate min on columns"
type StockCategories_min_fields {
  id: uuid
  organizationId: uuid
  value: String
}

"response of any mutation on the table \"StockCategories\""
type StockCategories_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [StockCategories!]!
}

"columns and relationships of \"Stocks\""
type Stocks {
  "An object relationship"
  Category: StockCategories
  "An object relationship"
  Organization: Organizations!
  categoryId: uuid!
  createdAt: timestamp!
  id: uuid!
  name: String!
  organizationId: uuid!
  pricePerUnit: numeric!
  unit: String
  updatedAt: timestamptz!
}

"aggregated selection of \"Stocks\""
type Stocks_aggregate {
  aggregate: Stocks_aggregate_fields
  nodes: [Stocks!]!
}

"aggregate fields of \"Stocks\""
type Stocks_aggregate_fields {
  avg: Stocks_avg_fields
  count(columns: [Stocks_select_column!], distinct: Boolean): Int!
  max: Stocks_max_fields
  min: Stocks_min_fields
  stddev: Stocks_stddev_fields
  stddev_pop: Stocks_stddev_pop_fields
  stddev_samp: Stocks_stddev_samp_fields
  sum: Stocks_sum_fields
  var_pop: Stocks_var_pop_fields
  var_samp: Stocks_var_samp_fields
  variance: Stocks_variance_fields
}

"aggregate avg on columns"
type Stocks_avg_fields {
  pricePerUnit: Float
}

"aggregate max on columns"
type Stocks_max_fields {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  pricePerUnit: numeric
  unit: String
  updatedAt: timestamptz
}

"aggregate min on columns"
type Stocks_min_fields {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  pricePerUnit: numeric
  unit: String
  updatedAt: timestamptz
}

"response of any mutation on the table \"Stocks\""
type Stocks_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Stocks!]!
}

"aggregate stddev on columns"
type Stocks_stddev_fields {
  pricePerUnit: Float
}

"aggregate stddev_pop on columns"
type Stocks_stddev_pop_fields {
  pricePerUnit: Float
}

"aggregate stddev_samp on columns"
type Stocks_stddev_samp_fields {
  pricePerUnit: Float
}

"aggregate sum on columns"
type Stocks_sum_fields {
  pricePerUnit: numeric
}

"aggregate var_pop on columns"
type Stocks_var_pop_fields {
  pricePerUnit: Float
}

"aggregate var_samp on columns"
type Stocks_var_samp_fields {
  pricePerUnit: Float
}

"aggregate variance on columns"
type Stocks_variance_fields {
  pricePerUnit: Float
}

"columns and relationships of \"Units\""
type Units {
  "An array relationship"
  InvoiceSections(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "An aggregate relationship"
  InvoiceSections_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): InvoiceSections_aggregate!
  "An object relationship"
  Organization: Organizations
  "An array relationship"
  QuotationSections(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "An aggregate relationship"
  QuotationSections_aggregate(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): QuotationSections_aggregate!
  organizationId: uuid!
  value: String!
}

"aggregated selection of \"Units\""
type Units_aggregate {
  aggregate: Units_aggregate_fields
  nodes: [Units!]!
}

"aggregate fields of \"Units\""
type Units_aggregate_fields {
  count(columns: [Units_select_column!], distinct: Boolean): Int!
  max: Units_max_fields
  min: Units_min_fields
}

"aggregate max on columns"
type Units_max_fields {
  organizationId: uuid
  value: String
}

"aggregate min on columns"
type Units_min_fields {
  organizationId: uuid
  value: String
}

"response of any mutation on the table \"Units\""
type Units_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [Units!]!
}

"columns and relationships of \"authorizer_email_templates\""
type authorizer_email_templates {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar!
  key: String
  subject: String
  template: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_email_templates\""
type authorizer_email_templates_aggregate {
  aggregate: authorizer_email_templates_aggregate_fields
  nodes: [authorizer_email_templates!]!
}

"aggregate fields of \"authorizer_email_templates\""
type authorizer_email_templates_aggregate_fields {
  avg: authorizer_email_templates_avg_fields
  count(columns: [authorizer_email_templates_select_column!], distinct: Boolean): Int!
  max: authorizer_email_templates_max_fields
  min: authorizer_email_templates_min_fields
  stddev: authorizer_email_templates_stddev_fields
  stddev_pop: authorizer_email_templates_stddev_pop_fields
  stddev_samp: authorizer_email_templates_stddev_samp_fields
  sum: authorizer_email_templates_sum_fields
  var_pop: authorizer_email_templates_var_pop_fields
  var_samp: authorizer_email_templates_var_samp_fields
  variance: authorizer_email_templates_variance_fields
}

"aggregate avg on columns"
type authorizer_email_templates_avg_fields {
  created_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_email_templates_max_fields {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar
  key: String
  subject: String
  template: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_email_templates_min_fields {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar
  key: String
  subject: String
  template: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_email_templates\""
type authorizer_email_templates_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_email_templates!]!
}

"aggregate stddev on columns"
type authorizer_email_templates_stddev_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_email_templates_stddev_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_email_templates_stddev_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_email_templates_sum_fields {
  created_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_email_templates_var_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_email_templates_var_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_email_templates_variance_fields {
  created_at: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_envs\""
type authorizer_envs {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar!
  key: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_envs\""
type authorizer_envs_aggregate {
  aggregate: authorizer_envs_aggregate_fields
  nodes: [authorizer_envs!]!
}

"aggregate fields of \"authorizer_envs\""
type authorizer_envs_aggregate_fields {
  avg: authorizer_envs_avg_fields
  count(columns: [authorizer_envs_select_column!], distinct: Boolean): Int!
  max: authorizer_envs_max_fields
  min: authorizer_envs_min_fields
  stddev: authorizer_envs_stddev_fields
  stddev_pop: authorizer_envs_stddev_pop_fields
  stddev_samp: authorizer_envs_stddev_samp_fields
  sum: authorizer_envs_sum_fields
  var_pop: authorizer_envs_var_pop_fields
  var_samp: authorizer_envs_var_samp_fields
  variance: authorizer_envs_variance_fields
}

"aggregate avg on columns"
type authorizer_envs_avg_fields {
  created_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_envs_max_fields {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar
  key: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_envs_min_fields {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar
  key: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_envs\""
type authorizer_envs_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_envs!]!
}

"aggregate stddev on columns"
type authorizer_envs_stddev_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_envs_stddev_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_envs_stddev_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_envs_sum_fields {
  created_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_envs_var_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_envs_var_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_envs_variance_fields {
  created_at: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_otps\""
type authorizer_otps {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar!
  key: String
  otp: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_otps\""
type authorizer_otps_aggregate {
  aggregate: authorizer_otps_aggregate_fields
  nodes: [authorizer_otps!]!
}

"aggregate fields of \"authorizer_otps\""
type authorizer_otps_aggregate_fields {
  avg: authorizer_otps_avg_fields
  count(columns: [authorizer_otps_select_column!], distinct: Boolean): Int!
  max: authorizer_otps_max_fields
  min: authorizer_otps_min_fields
  stddev: authorizer_otps_stddev_fields
  stddev_pop: authorizer_otps_stddev_pop_fields
  stddev_samp: authorizer_otps_stddev_samp_fields
  sum: authorizer_otps_sum_fields
  var_pop: authorizer_otps_var_pop_fields
  var_samp: authorizer_otps_var_samp_fields
  variance: authorizer_otps_variance_fields
}

"aggregate avg on columns"
type authorizer_otps_avg_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_otps_max_fields {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  key: String
  otp: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_otps_min_fields {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  key: String
  otp: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_otps\""
type authorizer_otps_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_otps!]!
}

"aggregate stddev on columns"
type authorizer_otps_stddev_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_otps_stddev_pop_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_otps_stddev_samp_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_otps_sum_fields {
  created_at: bigint
  expires_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_otps_var_pop_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_otps_var_samp_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_otps_variance_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_sessions\""
type authorizer_sessions {
  created_at: bigint
  id: bpchar!
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

"aggregated selection of \"authorizer_sessions\""
type authorizer_sessions_aggregate {
  aggregate: authorizer_sessions_aggregate_fields
  nodes: [authorizer_sessions!]!
}

"aggregate fields of \"authorizer_sessions\""
type authorizer_sessions_aggregate_fields {
  avg: authorizer_sessions_avg_fields
  count(columns: [authorizer_sessions_select_column!], distinct: Boolean): Int!
  max: authorizer_sessions_max_fields
  min: authorizer_sessions_min_fields
  stddev: authorizer_sessions_stddev_fields
  stddev_pop: authorizer_sessions_stddev_pop_fields
  stddev_samp: authorizer_sessions_stddev_samp_fields
  sum: authorizer_sessions_sum_fields
  var_pop: authorizer_sessions_var_pop_fields
  var_samp: authorizer_sessions_var_samp_fields
  variance: authorizer_sessions_variance_fields
}

"aggregate avg on columns"
type authorizer_sessions_avg_fields {
  created_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_sessions_max_fields {
  created_at: bigint
  id: bpchar
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

"aggregate min on columns"
type authorizer_sessions_min_fields {
  created_at: bigint
  id: bpchar
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

"response of any mutation on the table \"authorizer_sessions\""
type authorizer_sessions_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_sessions!]!
}

"aggregate stddev on columns"
type authorizer_sessions_stddev_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_sessions_stddev_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_sessions_stddev_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_sessions_sum_fields {
  created_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_sessions_var_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_sessions_var_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_sessions_variance_fields {
  created_at: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_users\""
type authorizer_users {
  "An array relationship"
  Organizations(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): [Organizations!]!
  "An aggregate relationship"
  Organizations_aggregate(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): Organizations_aggregate!
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar!
  is_multi_factor_auth_enabled: Boolean
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_users\""
type authorizer_users_aggregate {
  aggregate: authorizer_users_aggregate_fields
  nodes: [authorizer_users!]!
}

"aggregate fields of \"authorizer_users\""
type authorizer_users_aggregate_fields {
  avg: authorizer_users_avg_fields
  count(columns: [authorizer_users_select_column!], distinct: Boolean): Int!
  max: authorizer_users_max_fields
  min: authorizer_users_min_fields
  stddev: authorizer_users_stddev_fields
  stddev_pop: authorizer_users_stddev_pop_fields
  stddev_samp: authorizer_users_stddev_samp_fields
  sum: authorizer_users_sum_fields
  var_pop: authorizer_users_var_pop_fields
  var_samp: authorizer_users_var_samp_fields
  variance: authorizer_users_variance_fields
}

"aggregate avg on columns"
type authorizer_users_avg_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_users_max_fields {
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_users_min_fields {
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_users\""
type authorizer_users_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_users!]!
}

"aggregate stddev on columns"
type authorizer_users_stddev_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_users_stddev_pop_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_users_stddev_samp_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_users_sum_fields {
  created_at: bigint
  email_verified_at: bigint
  phone_number_verified_at: bigint
  revoked_timestamp: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_users_var_pop_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_users_var_samp_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_users_variance_fields {
  created_at: Float
  email_verified_at: Float
  phone_number_verified_at: Float
  revoked_timestamp: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_verification_requests\""
type authorizer_verification_requests {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar!
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_verification_requests\""
type authorizer_verification_requests_aggregate {
  aggregate: authorizer_verification_requests_aggregate_fields
  nodes: [authorizer_verification_requests!]!
}

"aggregate fields of \"authorizer_verification_requests\""
type authorizer_verification_requests_aggregate_fields {
  avg: authorizer_verification_requests_avg_fields
  count(columns: [authorizer_verification_requests_select_column!], distinct: Boolean): Int!
  max: authorizer_verification_requests_max_fields
  min: authorizer_verification_requests_min_fields
  stddev: authorizer_verification_requests_stddev_fields
  stddev_pop: authorizer_verification_requests_stddev_pop_fields
  stddev_samp: authorizer_verification_requests_stddev_samp_fields
  sum: authorizer_verification_requests_sum_fields
  var_pop: authorizer_verification_requests_var_pop_fields
  var_samp: authorizer_verification_requests_var_samp_fields
  variance: authorizer_verification_requests_variance_fields
}

"aggregate avg on columns"
type authorizer_verification_requests_avg_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_verification_requests_max_fields {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_verification_requests_min_fields {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_verification_requests\""
type authorizer_verification_requests_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_verification_requests!]!
}

"aggregate stddev on columns"
type authorizer_verification_requests_stddev_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_verification_requests_stddev_pop_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_verification_requests_stddev_samp_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_verification_requests_sum_fields {
  created_at: bigint
  expires_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_verification_requests_var_pop_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_verification_requests_var_samp_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_verification_requests_variance_fields {
  created_at: Float
  expires_at: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_webhook_logs\""
type authorizer_webhook_logs {
  created_at: bigint
  http_status: bigint
  id: bpchar!
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

"aggregated selection of \"authorizer_webhook_logs\""
type authorizer_webhook_logs_aggregate {
  aggregate: authorizer_webhook_logs_aggregate_fields
  nodes: [authorizer_webhook_logs!]!
}

"aggregate fields of \"authorizer_webhook_logs\""
type authorizer_webhook_logs_aggregate_fields {
  avg: authorizer_webhook_logs_avg_fields
  count(columns: [authorizer_webhook_logs_select_column!], distinct: Boolean): Int!
  max: authorizer_webhook_logs_max_fields
  min: authorizer_webhook_logs_min_fields
  stddev: authorizer_webhook_logs_stddev_fields
  stddev_pop: authorizer_webhook_logs_stddev_pop_fields
  stddev_samp: authorizer_webhook_logs_stddev_samp_fields
  sum: authorizer_webhook_logs_sum_fields
  var_pop: authorizer_webhook_logs_var_pop_fields
  var_samp: authorizer_webhook_logs_var_samp_fields
  variance: authorizer_webhook_logs_variance_fields
}

"aggregate avg on columns"
type authorizer_webhook_logs_avg_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_webhook_logs_max_fields {
  created_at: bigint
  http_status: bigint
  id: bpchar
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

"aggregate min on columns"
type authorizer_webhook_logs_min_fields {
  created_at: bigint
  http_status: bigint
  id: bpchar
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

"response of any mutation on the table \"authorizer_webhook_logs\""
type authorizer_webhook_logs_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_webhook_logs!]!
}

"aggregate stddev on columns"
type authorizer_webhook_logs_stddev_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_webhook_logs_stddev_pop_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_webhook_logs_stddev_samp_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_webhook_logs_sum_fields {
  created_at: bigint
  http_status: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_webhook_logs_var_pop_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_webhook_logs_var_samp_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_webhook_logs_variance_fields {
  created_at: Float
  http_status: Float
  updated_at: Float
}

"columns and relationships of \"authorizer_webhooks\""
type authorizer_webhooks {
  created_at: bigint
  enabled: Boolean
  end_point: String
  event_name: String
  headers: String
  id: bpchar!
  key: String
  updated_at: bigint
}

"aggregated selection of \"authorizer_webhooks\""
type authorizer_webhooks_aggregate {
  aggregate: authorizer_webhooks_aggregate_fields
  nodes: [authorizer_webhooks!]!
}

"aggregate fields of \"authorizer_webhooks\""
type authorizer_webhooks_aggregate_fields {
  avg: authorizer_webhooks_avg_fields
  count(columns: [authorizer_webhooks_select_column!], distinct: Boolean): Int!
  max: authorizer_webhooks_max_fields
  min: authorizer_webhooks_min_fields
  stddev: authorizer_webhooks_stddev_fields
  stddev_pop: authorizer_webhooks_stddev_pop_fields
  stddev_samp: authorizer_webhooks_stddev_samp_fields
  sum: authorizer_webhooks_sum_fields
  var_pop: authorizer_webhooks_var_pop_fields
  var_samp: authorizer_webhooks_var_samp_fields
  variance: authorizer_webhooks_variance_fields
}

"aggregate avg on columns"
type authorizer_webhooks_avg_fields {
  created_at: Float
  updated_at: Float
}

"aggregate max on columns"
type authorizer_webhooks_max_fields {
  created_at: bigint
  end_point: String
  event_name: String
  headers: String
  id: bpchar
  key: String
  updated_at: bigint
}

"aggregate min on columns"
type authorizer_webhooks_min_fields {
  created_at: bigint
  end_point: String
  event_name: String
  headers: String
  id: bpchar
  key: String
  updated_at: bigint
}

"response of any mutation on the table \"authorizer_webhooks\""
type authorizer_webhooks_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [authorizer_webhooks!]!
}

"aggregate stddev on columns"
type authorizer_webhooks_stddev_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_pop on columns"
type authorizer_webhooks_stddev_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate stddev_samp on columns"
type authorizer_webhooks_stddev_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate sum on columns"
type authorizer_webhooks_sum_fields {
  created_at: bigint
  updated_at: bigint
}

"aggregate var_pop on columns"
type authorizer_webhooks_var_pop_fields {
  created_at: Float
  updated_at: Float
}

"aggregate var_samp on columns"
type authorizer_webhooks_var_samp_fields {
  created_at: Float
  updated_at: Float
}

"aggregate variance on columns"
type authorizer_webhooks_variance_fields {
  created_at: Float
  updated_at: Float
}

"mutation root"
type mutation_root {
  "delete single row from the table: \"OrganizationClients\""
  deleteClient(id: uuid!): OrganizationClients
  "delete data from the table: \"OrganizationClients\""
  deleteClients(
    "filter the rows which have to be deleted"
    where: OrganizationClients_bool_exp!
  ): OrganizationClients_mutation_response
  "delete single row from the table: \"Invoices\""
  deleteInvoice(id: uuid!): Invoices
  "delete single row from the table: \"InvoiceSections\""
  deleteInvoiceSection(id: uuid!): InvoiceSections
  "delete single row from the table: \"InvoiceSectionItems\""
  deleteInvoiceSectionItem(id: uuid!): InvoiceSectionItems
  "delete data from the table: \"InvoiceSectionItems\""
  deleteInvoiceSectionItems(
    "filter the rows which have to be deleted"
    where: InvoiceSectionItems_bool_exp!
  ): InvoiceSectionItems_mutation_response
  "delete data from the table: \"InvoiceSections\""
  deleteInvoiceSections(
    "filter the rows which have to be deleted"
    where: InvoiceSections_bool_exp!
  ): InvoiceSections_mutation_response
  "delete single row from the table: \"InvoiceStatuses\""
  deleteInvoiceStatus(value: String!): InvoiceStatuses
  "delete data from the table: \"InvoiceStatuses\""
  deleteInvoiceStatuses(
    "filter the rows which have to be deleted"
    where: InvoiceStatuses_bool_exp!
  ): InvoiceStatuses_mutation_response
  "delete data from the table: \"Invoices\""
  deleteInvoices(
    "filter the rows which have to be deleted"
    where: Invoices_bool_exp!
  ): Invoices_mutation_response
  "delete single row from the table: \"QuotationSectionItems\""
  deleteOquotationSectionItem(id: uuid!): QuotationSectionItems
  "delete data from the table: \"QuotationSectionItems\""
  deleteOquotationSectionItems(
    "filter the rows which have to be deleted"
    where: QuotationSectionItems_bool_exp!
  ): QuotationSectionItems_mutation_response
  "delete single row from the table: \"Organizations\""
  deleteOrganization(id: uuid!): Organizations
  "delete data from the table: \"Organizations\""
  deleteOrganizations(
    "filter the rows which have to be deleted"
    where: Organizations_bool_exp!
  ): Organizations_mutation_response
  "delete single row from the table: \"Quotations\""
  deleteQuotation(id: uuid!): Quotations
  "delete single row from the table: \"QuotationSections\""
  deleteQuotationSection(id: uuid!): QuotationSections
  "delete data from the table: \"QuotationSections\""
  deleteQuotationSections(
    "filter the rows which have to be deleted"
    where: QuotationSections_bool_exp!
  ): QuotationSections_mutation_response
  "delete single row from the table: \"QuotationStatuses\""
  deleteQuotationStatus(value: String!): QuotationStatuses
  "delete data from the table: \"QuotationStatuses\""
  deleteQuotationStatuses(
    "filter the rows which have to be deleted"
    where: QuotationStatuses_bool_exp!
  ): QuotationStatuses_mutation_response
  "delete data from the table: \"Quotations\""
  deleteQuotations(
    "filter the rows which have to be deleted"
    where: Quotations_bool_exp!
  ): Quotations_mutation_response
  "delete single row from the table: \"Roles\""
  deleteRole(value: String!): Roles
  "delete data from the table: \"Roles\""
  deleteRoles(
    "filter the rows which have to be deleted"
    where: Roles_bool_exp!
  ): Roles_mutation_response
  "delete single row from the table: \"Stocks\""
  deleteStock(id: uuid!): Stocks
  "delete data from the table: \"Stocks\""
  deleteStocks(
    "filter the rows which have to be deleted"
    where: Stocks_bool_exp!
  ): Stocks_mutation_response
  "delete data from the table: \"InvoiceQuotationCategories\""
  delete_InvoiceQuotationCategories(
    "filter the rows which have to be deleted"
    where: InvoiceQuotationCategories_bool_exp!
  ): InvoiceQuotationCategories_mutation_response
  "delete single row from the table: \"InvoiceQuotationCategories\""
  delete_InvoiceQuotationCategories_by_pk(id: uuid!): InvoiceQuotationCategories
  "delete data from the table: \"StockCategories\""
  delete_StockCategories(
    "filter the rows which have to be deleted"
    where: StockCategories_bool_exp!
  ): StockCategories_mutation_response
  "delete single row from the table: \"StockCategories\""
  delete_StockCategories_by_pk(id: uuid!): StockCategories
  "delete data from the table: \"Units\""
  delete_Units(
    "filter the rows which have to be deleted"
    where: Units_bool_exp!
  ): Units_mutation_response
  "delete single row from the table: \"Units\""
  delete_Units_by_pk(value: String!): Units
  "delete data from the table: \"authorizer_email_templates\""
  delete_authorizer_email_templates(
    "filter the rows which have to be deleted"
    where: authorizer_email_templates_bool_exp!
  ): authorizer_email_templates_mutation_response
  "delete single row from the table: \"authorizer_email_templates\""
  delete_authorizer_email_templates_by_pk(id: bpchar!): authorizer_email_templates
  "delete data from the table: \"authorizer_envs\""
  delete_authorizer_envs(
    "filter the rows which have to be deleted"
    where: authorizer_envs_bool_exp!
  ): authorizer_envs_mutation_response
  "delete single row from the table: \"authorizer_envs\""
  delete_authorizer_envs_by_pk(id: bpchar!): authorizer_envs
  "delete data from the table: \"authorizer_otps\""
  delete_authorizer_otps(
    "filter the rows which have to be deleted"
    where: authorizer_otps_bool_exp!
  ): authorizer_otps_mutation_response
  "delete single row from the table: \"authorizer_otps\""
  delete_authorizer_otps_by_pk(id: bpchar!): authorizer_otps
  "delete data from the table: \"authorizer_sessions\""
  delete_authorizer_sessions(
    "filter the rows which have to be deleted"
    where: authorizer_sessions_bool_exp!
  ): authorizer_sessions_mutation_response
  "delete single row from the table: \"authorizer_sessions\""
  delete_authorizer_sessions_by_pk(id: bpchar!): authorizer_sessions
  "delete data from the table: \"authorizer_users\""
  delete_authorizer_users(
    "filter the rows which have to be deleted"
    where: authorizer_users_bool_exp!
  ): authorizer_users_mutation_response
  "delete single row from the table: \"authorizer_users\""
  delete_authorizer_users_by_pk(id: bpchar!): authorizer_users
  "delete data from the table: \"authorizer_verification_requests\""
  delete_authorizer_verification_requests(
    "filter the rows which have to be deleted"
    where: authorizer_verification_requests_bool_exp!
  ): authorizer_verification_requests_mutation_response
  "delete single row from the table: \"authorizer_verification_requests\""
  delete_authorizer_verification_requests_by_pk(id: bpchar!): authorizer_verification_requests
  "delete data from the table: \"authorizer_webhook_logs\""
  delete_authorizer_webhook_logs(
    "filter the rows which have to be deleted"
    where: authorizer_webhook_logs_bool_exp!
  ): authorizer_webhook_logs_mutation_response
  "delete single row from the table: \"authorizer_webhook_logs\""
  delete_authorizer_webhook_logs_by_pk(id: bpchar!): authorizer_webhook_logs
  "delete data from the table: \"authorizer_webhooks\""
  delete_authorizer_webhooks(
    "filter the rows which have to be deleted"
    where: authorizer_webhooks_bool_exp!
  ): authorizer_webhooks_mutation_response
  "delete single row from the table: \"authorizer_webhooks\""
  delete_authorizer_webhooks_by_pk(id: bpchar!): authorizer_webhooks
  "insert data into the table: \"QuotationSectionItems\""
  inserOquotationSectionItems(
    "the rows to be inserted"
    objects: [QuotationSectionItems_insert_input!]!,
    "upsert condition"
    on_conflict: QuotationSectionItems_on_conflict
  ): QuotationSectionItems_mutation_response
  "insert a single row into the table: \"OrganizationClients\""
  insertClient(
    "the row to be inserted"
    object: OrganizationClients_insert_input!,
    "upsert condition"
    on_conflict: OrganizationClients_on_conflict
  ): OrganizationClients
  "insert data into the table: \"OrganizationClients\""
  insertClients(
    "the rows to be inserted"
    objects: [OrganizationClients_insert_input!]!,
    "upsert condition"
    on_conflict: OrganizationClients_on_conflict
  ): OrganizationClients_mutation_response
  "insert a single row into the table: \"Invoices\""
  insertInvoice(
    "the row to be inserted"
    object: Invoices_insert_input!,
    "upsert condition"
    on_conflict: Invoices_on_conflict
  ): Invoices
  "insert a single row into the table: \"InvoiceSections\""
  insertInvoiceSection(
    "the row to be inserted"
    object: InvoiceSections_insert_input!,
    "upsert condition"
    on_conflict: InvoiceSections_on_conflict
  ): InvoiceSections
  "insert a single row into the table: \"InvoiceSectionItems\""
  insertInvoiceSectionItem(
    "the row to be inserted"
    object: InvoiceSectionItems_insert_input!,
    "upsert condition"
    on_conflict: InvoiceSectionItems_on_conflict
  ): InvoiceSectionItems
  "insert data into the table: \"InvoiceSectionItems\""
  insertInvoiceSectionItems(
    "the rows to be inserted"
    objects: [InvoiceSectionItems_insert_input!]!,
    "upsert condition"
    on_conflict: InvoiceSectionItems_on_conflict
  ): InvoiceSectionItems_mutation_response
  "insert data into the table: \"InvoiceSections\""
  insertInvoiceSections(
    "the rows to be inserted"
    objects: [InvoiceSections_insert_input!]!,
    "upsert condition"
    on_conflict: InvoiceSections_on_conflict
  ): InvoiceSections_mutation_response
  "insert a single row into the table: \"InvoiceStatuses\""
  insertInvoiceStatus(
    "the row to be inserted"
    object: InvoiceStatuses_insert_input!,
    "upsert condition"
    on_conflict: InvoiceStatuses_on_conflict
  ): InvoiceStatuses
  "insert data into the table: \"InvoiceStatuses\""
  insertInvoiceStatuses(
    "the rows to be inserted"
    objects: [InvoiceStatuses_insert_input!]!,
    "upsert condition"
    on_conflict: InvoiceStatuses_on_conflict
  ): InvoiceStatuses_mutation_response
  "insert data into the table: \"Invoices\""
  insertInvoices(
    "the rows to be inserted"
    objects: [Invoices_insert_input!]!,
    "upsert condition"
    on_conflict: Invoices_on_conflict
  ): Invoices_mutation_response
  "insert a single row into the table: \"QuotationSectionItems\""
  insertOquotationSectionItem(
    "the row to be inserted"
    object: QuotationSectionItems_insert_input!,
    "upsert condition"
    on_conflict: QuotationSectionItems_on_conflict
  ): QuotationSectionItems
  "insert a single row into the table: \"Organizations\""
  insertOrganization(
    "the row to be inserted"
    object: Organizations_insert_input!,
    "upsert condition"
    on_conflict: Organizations_on_conflict
  ): Organizations
  "insert data into the table: \"Organizations\""
  insertOrganizations(
    "the rows to be inserted"
    objects: [Organizations_insert_input!]!,
    "upsert condition"
    on_conflict: Organizations_on_conflict
  ): Organizations_mutation_response
  "insert a single row into the table: \"Quotations\""
  insertQuotation(
    "the row to be inserted"
    object: Quotations_insert_input!,
    "upsert condition"
    on_conflict: Quotations_on_conflict
  ): Quotations
  "insert a single row into the table: \"QuotationSections\""
  insertQuotationSection(
    "the row to be inserted"
    object: QuotationSections_insert_input!,
    "upsert condition"
    on_conflict: QuotationSections_on_conflict
  ): QuotationSections
  "insert data into the table: \"QuotationSections\""
  insertQuotationSections(
    "the rows to be inserted"
    objects: [QuotationSections_insert_input!]!,
    "upsert condition"
    on_conflict: QuotationSections_on_conflict
  ): QuotationSections_mutation_response
  "insert a single row into the table: \"QuotationStatuses\""
  insertQuotationStatus(
    "the row to be inserted"
    object: QuotationStatuses_insert_input!,
    "upsert condition"
    on_conflict: QuotationStatuses_on_conflict
  ): QuotationStatuses
  "insert data into the table: \"QuotationStatuses\""
  insertQuotationStatuses(
    "the rows to be inserted"
    objects: [QuotationStatuses_insert_input!]!,
    "upsert condition"
    on_conflict: QuotationStatuses_on_conflict
  ): QuotationStatuses_mutation_response
  "insert data into the table: \"Quotations\""
  insertQuotations(
    "the rows to be inserted"
    objects: [Quotations_insert_input!]!,
    "upsert condition"
    on_conflict: Quotations_on_conflict
  ): Quotations_mutation_response
  "insert a single row into the table: \"Roles\""
  insertRole(
    "the row to be inserted"
    object: Roles_insert_input!,
    "upsert condition"
    on_conflict: Roles_on_conflict
  ): Roles
  "insert data into the table: \"Roles\""
  insertRoles(
    "the rows to be inserted"
    objects: [Roles_insert_input!]!,
    "upsert condition"
    on_conflict: Roles_on_conflict
  ): Roles_mutation_response
  "insert a single row into the table: \"Stocks\""
  insertStock(
    "the row to be inserted"
    object: Stocks_insert_input!,
    "upsert condition"
    on_conflict: Stocks_on_conflict
  ): Stocks
  "insert data into the table: \"Stocks\""
  insertStocks(
    "the rows to be inserted"
    objects: [Stocks_insert_input!]!,
    "upsert condition"
    on_conflict: Stocks_on_conflict
  ): Stocks_mutation_response
  "insert data into the table: \"InvoiceQuotationCategories\""
  insert_InvoiceQuotationCategories(
    "the rows to be inserted"
    objects: [InvoiceQuotationCategories_insert_input!]!,
    "upsert condition"
    on_conflict: InvoiceQuotationCategories_on_conflict
  ): InvoiceQuotationCategories_mutation_response
  "insert a single row into the table: \"InvoiceQuotationCategories\""
  insert_InvoiceQuotationCategories_one(
    "the row to be inserted"
    object: InvoiceQuotationCategories_insert_input!,
    "upsert condition"
    on_conflict: InvoiceQuotationCategories_on_conflict
  ): InvoiceQuotationCategories
  "insert data into the table: \"StockCategories\""
  insert_StockCategories(
    "the rows to be inserted"
    objects: [StockCategories_insert_input!]!,
    "upsert condition"
    on_conflict: StockCategories_on_conflict
  ): StockCategories_mutation_response
  "insert a single row into the table: \"StockCategories\""
  insert_StockCategories_one(
    "the row to be inserted"
    object: StockCategories_insert_input!,
    "upsert condition"
    on_conflict: StockCategories_on_conflict
  ): StockCategories
  "insert data into the table: \"Units\""
  insert_Units(
    "the rows to be inserted"
    objects: [Units_insert_input!]!,
    "upsert condition"
    on_conflict: Units_on_conflict
  ): Units_mutation_response
  "insert a single row into the table: \"Units\""
  insert_Units_one(
    "the row to be inserted"
    object: Units_insert_input!,
    "upsert condition"
    on_conflict: Units_on_conflict
  ): Units
  "insert data into the table: \"authorizer_email_templates\""
  insert_authorizer_email_templates(
    "the rows to be inserted"
    objects: [authorizer_email_templates_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_email_templates_on_conflict
  ): authorizer_email_templates_mutation_response
  "insert a single row into the table: \"authorizer_email_templates\""
  insert_authorizer_email_templates_one(
    "the row to be inserted"
    object: authorizer_email_templates_insert_input!,
    "upsert condition"
    on_conflict: authorizer_email_templates_on_conflict
  ): authorizer_email_templates
  "insert data into the table: \"authorizer_envs\""
  insert_authorizer_envs(
    "the rows to be inserted"
    objects: [authorizer_envs_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_envs_on_conflict
  ): authorizer_envs_mutation_response
  "insert a single row into the table: \"authorizer_envs\""
  insert_authorizer_envs_one(
    "the row to be inserted"
    object: authorizer_envs_insert_input!,
    "upsert condition"
    on_conflict: authorizer_envs_on_conflict
  ): authorizer_envs
  "insert data into the table: \"authorizer_otps\""
  insert_authorizer_otps(
    "the rows to be inserted"
    objects: [authorizer_otps_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_otps_on_conflict
  ): authorizer_otps_mutation_response
  "insert a single row into the table: \"authorizer_otps\""
  insert_authorizer_otps_one(
    "the row to be inserted"
    object: authorizer_otps_insert_input!,
    "upsert condition"
    on_conflict: authorizer_otps_on_conflict
  ): authorizer_otps
  "insert data into the table: \"authorizer_sessions\""
  insert_authorizer_sessions(
    "the rows to be inserted"
    objects: [authorizer_sessions_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_sessions_on_conflict
  ): authorizer_sessions_mutation_response
  "insert a single row into the table: \"authorizer_sessions\""
  insert_authorizer_sessions_one(
    "the row to be inserted"
    object: authorizer_sessions_insert_input!,
    "upsert condition"
    on_conflict: authorizer_sessions_on_conflict
  ): authorizer_sessions
  "insert data into the table: \"authorizer_users\""
  insert_authorizer_users(
    "the rows to be inserted"
    objects: [authorizer_users_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_users_on_conflict
  ): authorizer_users_mutation_response
  "insert a single row into the table: \"authorizer_users\""
  insert_authorizer_users_one(
    "the row to be inserted"
    object: authorizer_users_insert_input!,
    "upsert condition"
    on_conflict: authorizer_users_on_conflict
  ): authorizer_users
  "insert data into the table: \"authorizer_verification_requests\""
  insert_authorizer_verification_requests(
    "the rows to be inserted"
    objects: [authorizer_verification_requests_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_verification_requests_on_conflict
  ): authorizer_verification_requests_mutation_response
  "insert a single row into the table: \"authorizer_verification_requests\""
  insert_authorizer_verification_requests_one(
    "the row to be inserted"
    object: authorizer_verification_requests_insert_input!,
    "upsert condition"
    on_conflict: authorizer_verification_requests_on_conflict
  ): authorizer_verification_requests
  "insert data into the table: \"authorizer_webhook_logs\""
  insert_authorizer_webhook_logs(
    "the rows to be inserted"
    objects: [authorizer_webhook_logs_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_webhook_logs_on_conflict
  ): authorizer_webhook_logs_mutation_response
  "insert a single row into the table: \"authorizer_webhook_logs\""
  insert_authorizer_webhook_logs_one(
    "the row to be inserted"
    object: authorizer_webhook_logs_insert_input!,
    "upsert condition"
    on_conflict: authorizer_webhook_logs_on_conflict
  ): authorizer_webhook_logs
  "insert data into the table: \"authorizer_webhooks\""
  insert_authorizer_webhooks(
    "the rows to be inserted"
    objects: [authorizer_webhooks_insert_input!]!,
    "upsert condition"
    on_conflict: authorizer_webhooks_on_conflict
  ): authorizer_webhooks_mutation_response
  "insert a single row into the table: \"authorizer_webhooks\""
  insert_authorizer_webhooks_one(
    "the row to be inserted"
    object: authorizer_webhooks_insert_input!,
    "upsert condition"
    on_conflict: authorizer_webhooks_on_conflict
  ): authorizer_webhooks
  "update single row of the table: \"OrganizationClients\""
  updateClient(
    "sets the columns of the filtered rows to the given values"
    _set: OrganizationClients_set_input,
    pk_columns: OrganizationClients_pk_columns_input!
  ): OrganizationClients
  "update data of the table: \"OrganizationClients\""
  updateClients(
    "sets the columns of the filtered rows to the given values"
    _set: OrganizationClients_set_input,
    "filter the rows which have to be updated"
    where: OrganizationClients_bool_exp!
  ): OrganizationClients_mutation_response
  "update single row of the table: \"Invoices\""
  updateInvoice(
    "increments the numeric columns with given value of the filtered values"
    _inc: Invoices_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Invoices_set_input,
    pk_columns: Invoices_pk_columns_input!
  ): Invoices
  "update single row of the table: \"InvoiceSections\""
  updateInvoiceSection(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceSections_set_input,
    pk_columns: InvoiceSections_pk_columns_input!
  ): InvoiceSections
  "update single row of the table: \"InvoiceSectionItems\""
  updateInvoiceSectionItem(
    "increments the numeric columns with given value of the filtered values"
    _inc: InvoiceSectionItems_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceSectionItems_set_input,
    pk_columns: InvoiceSectionItems_pk_columns_input!
  ): InvoiceSectionItems
  "update data of the table: \"InvoiceSectionItems\""
  updateInvoiceSectionItems(
    "increments the numeric columns with given value of the filtered values"
    _inc: InvoiceSectionItems_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceSectionItems_set_input,
    "filter the rows which have to be updated"
    where: InvoiceSectionItems_bool_exp!
  ): InvoiceSectionItems_mutation_response
  "update data of the table: \"InvoiceSections\""
  updateInvoiceSections(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceSections_set_input,
    "filter the rows which have to be updated"
    where: InvoiceSections_bool_exp!
  ): InvoiceSections_mutation_response
  "update single row of the table: \"InvoiceStatuses\""
  updateInvoiceStatus(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceStatuses_set_input,
    pk_columns: InvoiceStatuses_pk_columns_input!
  ): InvoiceStatuses
  "update data of the table: \"InvoiceStatuses\""
  updateInvoiceStatuses(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceStatuses_set_input,
    "filter the rows which have to be updated"
    where: InvoiceStatuses_bool_exp!
  ): InvoiceStatuses_mutation_response
  "update data of the table: \"Invoices\""
  updateInvoices(
    "increments the numeric columns with given value of the filtered values"
    _inc: Invoices_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Invoices_set_input,
    "filter the rows which have to be updated"
    where: Invoices_bool_exp!
  ): Invoices_mutation_response
  "update multiples rows of table: \"OrganizationClients\""
  updateManyClients(
    "updates to execute, in order"
    updates: [OrganizationClients_updates!]!
  ): [OrganizationClients_mutation_response]
  "update multiples rows of table: \"InvoiceSectionItems\""
  updateManyInvoiceSectionItems(
    "updates to execute, in order"
    updates: [InvoiceSectionItems_updates!]!
  ): [InvoiceSectionItems_mutation_response]
  "update multiples rows of table: \"InvoiceSections\""
  updateManyInvoiceSections(
    "updates to execute, in order"
    updates: [InvoiceSections_updates!]!
  ): [InvoiceSections_mutation_response]
  "update multiples rows of table: \"InvoiceStatuses\""
  updateManyInvoiceStatuses(
    "updates to execute, in order"
    updates: [InvoiceStatuses_updates!]!
  ): [InvoiceStatuses_mutation_response]
  "update multiples rows of table: \"Invoices\""
  updateManyInvoices(
    "updates to execute, in order"
    updates: [Invoices_updates!]!
  ): [Invoices_mutation_response]
  "update multiples rows of table: \"QuotationSectionItems\""
  updateManyOquotationSectionItems(
    "updates to execute, in order"
    updates: [QuotationSectionItems_updates!]!
  ): [QuotationSectionItems_mutation_response]
  "update multiples rows of table: \"Organizations\""
  updateManyOrganizations(
    "updates to execute, in order"
    updates: [Organizations_updates!]!
  ): [Organizations_mutation_response]
  "update multiples rows of table: \"QuotationSections\""
  updateManyQuotationSections(
    "updates to execute, in order"
    updates: [QuotationSections_updates!]!
  ): [QuotationSections_mutation_response]
  "update multiples rows of table: \"QuotationStatuses\""
  updateManyQuotationStatuses(
    "updates to execute, in order"
    updates: [QuotationStatuses_updates!]!
  ): [QuotationStatuses_mutation_response]
  "update multiples rows of table: \"Quotations\""
  updateManyQuotations(
    "updates to execute, in order"
    updates: [Quotations_updates!]!
  ): [Quotations_mutation_response]
  "update multiples rows of table: \"Roles\""
  updateManyRoles(
    "updates to execute, in order"
    updates: [Roles_updates!]!
  ): [Roles_mutation_response]
  "update multiples rows of table: \"Stocks\""
  updateManyStocks(
    "updates to execute, in order"
    updates: [Stocks_updates!]!
  ): [Stocks_mutation_response]
  "update single row of the table: \"QuotationSectionItems\""
  updateOquotationSectionItem(
    "increments the numeric columns with given value of the filtered values"
    _inc: QuotationSectionItems_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: QuotationSectionItems_set_input,
    pk_columns: QuotationSectionItems_pk_columns_input!
  ): QuotationSectionItems
  "update data of the table: \"QuotationSectionItems\""
  updateOquotationSectionItems(
    "increments the numeric columns with given value of the filtered values"
    _inc: QuotationSectionItems_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: QuotationSectionItems_set_input,
    "filter the rows which have to be updated"
    where: QuotationSectionItems_bool_exp!
  ): QuotationSectionItems_mutation_response
  "update single row of the table: \"Organizations\""
  updateOrganization(
    "sets the columns of the filtered rows to the given values"
    _set: Organizations_set_input,
    pk_columns: Organizations_pk_columns_input!
  ): Organizations
  "update data of the table: \"Organizations\""
  updateOrganizations(
    "sets the columns of the filtered rows to the given values"
    _set: Organizations_set_input,
    "filter the rows which have to be updated"
    where: Organizations_bool_exp!
  ): Organizations_mutation_response
  "update single row of the table: \"Quotations\""
  updateQuotation(
    "increments the numeric columns with given value of the filtered values"
    _inc: Quotations_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Quotations_set_input,
    pk_columns: Quotations_pk_columns_input!
  ): Quotations
  "update single row of the table: \"QuotationSections\""
  updateQuotationSection(
    "sets the columns of the filtered rows to the given values"
    _set: QuotationSections_set_input,
    pk_columns: QuotationSections_pk_columns_input!
  ): QuotationSections
  "update data of the table: \"QuotationSections\""
  updateQuotationSections(
    "sets the columns of the filtered rows to the given values"
    _set: QuotationSections_set_input,
    "filter the rows which have to be updated"
    where: QuotationSections_bool_exp!
  ): QuotationSections_mutation_response
  "update single row of the table: \"QuotationStatuses\""
  updateQuotationStatus(
    "sets the columns of the filtered rows to the given values"
    _set: QuotationStatuses_set_input,
    pk_columns: QuotationStatuses_pk_columns_input!
  ): QuotationStatuses
  "update data of the table: \"QuotationStatuses\""
  updateQuotationStatuses(
    "sets the columns of the filtered rows to the given values"
    _set: QuotationStatuses_set_input,
    "filter the rows which have to be updated"
    where: QuotationStatuses_bool_exp!
  ): QuotationStatuses_mutation_response
  "update data of the table: \"Quotations\""
  updateQuotations(
    "increments the numeric columns with given value of the filtered values"
    _inc: Quotations_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Quotations_set_input,
    "filter the rows which have to be updated"
    where: Quotations_bool_exp!
  ): Quotations_mutation_response
  "update single row of the table: \"Roles\""
  updateRole(
    "sets the columns of the filtered rows to the given values"
    _set: Roles_set_input,
    pk_columns: Roles_pk_columns_input!
  ): Roles
  "update data of the table: \"Roles\""
  updateRoles(
    "sets the columns of the filtered rows to the given values"
    _set: Roles_set_input,
    "filter the rows which have to be updated"
    where: Roles_bool_exp!
  ): Roles_mutation_response
  "update single row of the table: \"Stocks\""
  updateStock(
    "increments the numeric columns with given value of the filtered values"
    _inc: Stocks_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Stocks_set_input,
    pk_columns: Stocks_pk_columns_input!
  ): Stocks
  "update data of the table: \"Stocks\""
  updateStocks(
    "increments the numeric columns with given value of the filtered values"
    _inc: Stocks_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: Stocks_set_input,
    "filter the rows which have to be updated"
    where: Stocks_bool_exp!
  ): Stocks_mutation_response
  "update data of the table: \"InvoiceQuotationCategories\""
  update_InvoiceQuotationCategories(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceQuotationCategories_set_input,
    "filter the rows which have to be updated"
    where: InvoiceQuotationCategories_bool_exp!
  ): InvoiceQuotationCategories_mutation_response
  "update single row of the table: \"InvoiceQuotationCategories\""
  update_InvoiceQuotationCategories_by_pk(
    "sets the columns of the filtered rows to the given values"
    _set: InvoiceQuotationCategories_set_input,
    pk_columns: InvoiceQuotationCategories_pk_columns_input!
  ): InvoiceQuotationCategories
  "update multiples rows of table: \"InvoiceQuotationCategories\""
  update_InvoiceQuotationCategories_many(
    "updates to execute, in order"
    updates: [InvoiceQuotationCategories_updates!]!
  ): [InvoiceQuotationCategories_mutation_response]
  "update data of the table: \"StockCategories\""
  update_StockCategories(
    "sets the columns of the filtered rows to the given values"
    _set: StockCategories_set_input,
    "filter the rows which have to be updated"
    where: StockCategories_bool_exp!
  ): StockCategories_mutation_response
  "update single row of the table: \"StockCategories\""
  update_StockCategories_by_pk(
    "sets the columns of the filtered rows to the given values"
    _set: StockCategories_set_input,
    pk_columns: StockCategories_pk_columns_input!
  ): StockCategories
  "update multiples rows of table: \"StockCategories\""
  update_StockCategories_many(
    "updates to execute, in order"
    updates: [StockCategories_updates!]!
  ): [StockCategories_mutation_response]
  "update data of the table: \"Units\""
  update_Units(
    "sets the columns of the filtered rows to the given values"
    _set: Units_set_input,
    "filter the rows which have to be updated"
    where: Units_bool_exp!
  ): Units_mutation_response
  "update single row of the table: \"Units\""
  update_Units_by_pk(
    "sets the columns of the filtered rows to the given values"
    _set: Units_set_input,
    pk_columns: Units_pk_columns_input!
  ): Units
  "update multiples rows of table: \"Units\""
  update_Units_many(
    "updates to execute, in order"
    updates: [Units_updates!]!
  ): [Units_mutation_response]
  "update data of the table: \"authorizer_email_templates\""
  update_authorizer_email_templates(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_email_templates_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_email_templates_set_input,
    "filter the rows which have to be updated"
    where: authorizer_email_templates_bool_exp!
  ): authorizer_email_templates_mutation_response
  "update single row of the table: \"authorizer_email_templates\""
  update_authorizer_email_templates_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_email_templates_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_email_templates_set_input,
    pk_columns: authorizer_email_templates_pk_columns_input!
  ): authorizer_email_templates
  "update multiples rows of table: \"authorizer_email_templates\""
  update_authorizer_email_templates_many(
    "updates to execute, in order"
    updates: [authorizer_email_templates_updates!]!
  ): [authorizer_email_templates_mutation_response]
  "update data of the table: \"authorizer_envs\""
  update_authorizer_envs(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_envs_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_envs_set_input,
    "filter the rows which have to be updated"
    where: authorizer_envs_bool_exp!
  ): authorizer_envs_mutation_response
  "update single row of the table: \"authorizer_envs\""
  update_authorizer_envs_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_envs_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_envs_set_input,
    pk_columns: authorizer_envs_pk_columns_input!
  ): authorizer_envs
  "update multiples rows of table: \"authorizer_envs\""
  update_authorizer_envs_many(
    "updates to execute, in order"
    updates: [authorizer_envs_updates!]!
  ): [authorizer_envs_mutation_response]
  "update data of the table: \"authorizer_otps\""
  update_authorizer_otps(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_otps_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_otps_set_input,
    "filter the rows which have to be updated"
    where: authorizer_otps_bool_exp!
  ): authorizer_otps_mutation_response
  "update single row of the table: \"authorizer_otps\""
  update_authorizer_otps_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_otps_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_otps_set_input,
    pk_columns: authorizer_otps_pk_columns_input!
  ): authorizer_otps
  "update multiples rows of table: \"authorizer_otps\""
  update_authorizer_otps_many(
    "updates to execute, in order"
    updates: [authorizer_otps_updates!]!
  ): [authorizer_otps_mutation_response]
  "update data of the table: \"authorizer_sessions\""
  update_authorizer_sessions(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_sessions_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_sessions_set_input,
    "filter the rows which have to be updated"
    where: authorizer_sessions_bool_exp!
  ): authorizer_sessions_mutation_response
  "update single row of the table: \"authorizer_sessions\""
  update_authorizer_sessions_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_sessions_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_sessions_set_input,
    pk_columns: authorizer_sessions_pk_columns_input!
  ): authorizer_sessions
  "update multiples rows of table: \"authorizer_sessions\""
  update_authorizer_sessions_many(
    "updates to execute, in order"
    updates: [authorizer_sessions_updates!]!
  ): [authorizer_sessions_mutation_response]
  "update data of the table: \"authorizer_users\""
  update_authorizer_users(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_users_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_users_set_input,
    "filter the rows which have to be updated"
    where: authorizer_users_bool_exp!
  ): authorizer_users_mutation_response
  "update single row of the table: \"authorizer_users\""
  update_authorizer_users_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_users_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_users_set_input,
    pk_columns: authorizer_users_pk_columns_input!
  ): authorizer_users
  "update multiples rows of table: \"authorizer_users\""
  update_authorizer_users_many(
    "updates to execute, in order"
    updates: [authorizer_users_updates!]!
  ): [authorizer_users_mutation_response]
  "update data of the table: \"authorizer_verification_requests\""
  update_authorizer_verification_requests(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_verification_requests_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_verification_requests_set_input,
    "filter the rows which have to be updated"
    where: authorizer_verification_requests_bool_exp!
  ): authorizer_verification_requests_mutation_response
  "update single row of the table: \"authorizer_verification_requests\""
  update_authorizer_verification_requests_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_verification_requests_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_verification_requests_set_input,
    pk_columns: authorizer_verification_requests_pk_columns_input!
  ): authorizer_verification_requests
  "update multiples rows of table: \"authorizer_verification_requests\""
  update_authorizer_verification_requests_many(
    "updates to execute, in order"
    updates: [authorizer_verification_requests_updates!]!
  ): [authorizer_verification_requests_mutation_response]
  "update data of the table: \"authorizer_webhook_logs\""
  update_authorizer_webhook_logs(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_webhook_logs_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_webhook_logs_set_input,
    "filter the rows which have to be updated"
    where: authorizer_webhook_logs_bool_exp!
  ): authorizer_webhook_logs_mutation_response
  "update single row of the table: \"authorizer_webhook_logs\""
  update_authorizer_webhook_logs_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_webhook_logs_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_webhook_logs_set_input,
    pk_columns: authorizer_webhook_logs_pk_columns_input!
  ): authorizer_webhook_logs
  "update multiples rows of table: \"authorizer_webhook_logs\""
  update_authorizer_webhook_logs_many(
    "updates to execute, in order"
    updates: [authorizer_webhook_logs_updates!]!
  ): [authorizer_webhook_logs_mutation_response]
  "update data of the table: \"authorizer_webhooks\""
  update_authorizer_webhooks(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_webhooks_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_webhooks_set_input,
    "filter the rows which have to be updated"
    where: authorizer_webhooks_bool_exp!
  ): authorizer_webhooks_mutation_response
  "update single row of the table: \"authorizer_webhooks\""
  update_authorizer_webhooks_by_pk(
    "increments the numeric columns with given value of the filtered values"
    _inc: authorizer_webhooks_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: authorizer_webhooks_set_input,
    pk_columns: authorizer_webhooks_pk_columns_input!
  ): authorizer_webhooks
  "update multiples rows of table: \"authorizer_webhooks\""
  update_authorizer_webhooks_many(
    "updates to execute, in order"
    updates: [authorizer_webhooks_updates!]!
  ): [authorizer_webhooks_mutation_response]
}

type query_root {
  "fetch data from the table: \"InvoiceQuotationCategories\""
  InvoiceQuotationCategories(
    "distinct select on columns"
    distinct_on: [InvoiceQuotationCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceQuotationCategories_order_by!],
    "filter the rows returned"
    where: InvoiceQuotationCategories_bool_exp
  ): [InvoiceQuotationCategories!]!
  "fetch aggregated fields from the table: \"InvoiceQuotationCategories\""
  InvoiceQuotationCategories_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceQuotationCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceQuotationCategories_order_by!],
    "filter the rows returned"
    where: InvoiceQuotationCategories_bool_exp
  ): InvoiceQuotationCategories_aggregate!
  "fetch data from the table: \"InvoiceQuotationCategories\" using primary key columns"
  InvoiceQuotationCategories_by_pk(id: uuid!): InvoiceQuotationCategories
  "fetch data from the table: \"StockCategories\""
  StockCategories(
    "distinct select on columns"
    distinct_on: [StockCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [StockCategories_order_by!],
    "filter the rows returned"
    where: StockCategories_bool_exp
  ): [StockCategories!]!
  "fetch aggregated fields from the table: \"StockCategories\""
  StockCategories_aggregate(
    "distinct select on columns"
    distinct_on: [StockCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [StockCategories_order_by!],
    "filter the rows returned"
    where: StockCategories_bool_exp
  ): StockCategories_aggregate!
  "fetch data from the table: \"StockCategories\" using primary key columns"
  StockCategories_by_pk(id: uuid!): StockCategories
  "fetch data from the table: \"Units\""
  Units(
    "distinct select on columns"
    distinct_on: [Units_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Units_order_by!],
    "filter the rows returned"
    where: Units_bool_exp
  ): [Units!]!
  "fetch aggregated fields from the table: \"Units\""
  Units_aggregate(
    "distinct select on columns"
    distinct_on: [Units_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Units_order_by!],
    "filter the rows returned"
    where: Units_bool_exp
  ): Units_aggregate!
  "fetch data from the table: \"Units\" using primary key columns"
  Units_by_pk(value: String!): Units
  "fetch data from the table: \"authorizer_email_templates\""
  authorizer_email_templates(
    "distinct select on columns"
    distinct_on: [authorizer_email_templates_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_email_templates_order_by!],
    "filter the rows returned"
    where: authorizer_email_templates_bool_exp
  ): [authorizer_email_templates!]!
  "fetch aggregated fields from the table: \"authorizer_email_templates\""
  authorizer_email_templates_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_email_templates_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_email_templates_order_by!],
    "filter the rows returned"
    where: authorizer_email_templates_bool_exp
  ): authorizer_email_templates_aggregate!
  "fetch data from the table: \"authorizer_email_templates\" using primary key columns"
  authorizer_email_templates_by_pk(id: bpchar!): authorizer_email_templates
  "fetch data from the table: \"authorizer_envs\""
  authorizer_envs(
    "distinct select on columns"
    distinct_on: [authorizer_envs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_envs_order_by!],
    "filter the rows returned"
    where: authorizer_envs_bool_exp
  ): [authorizer_envs!]!
  "fetch aggregated fields from the table: \"authorizer_envs\""
  authorizer_envs_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_envs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_envs_order_by!],
    "filter the rows returned"
    where: authorizer_envs_bool_exp
  ): authorizer_envs_aggregate!
  "fetch data from the table: \"authorizer_envs\" using primary key columns"
  authorizer_envs_by_pk(id: bpchar!): authorizer_envs
  "fetch data from the table: \"authorizer_otps\""
  authorizer_otps(
    "distinct select on columns"
    distinct_on: [authorizer_otps_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_otps_order_by!],
    "filter the rows returned"
    where: authorizer_otps_bool_exp
  ): [authorizer_otps!]!
  "fetch aggregated fields from the table: \"authorizer_otps\""
  authorizer_otps_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_otps_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_otps_order_by!],
    "filter the rows returned"
    where: authorizer_otps_bool_exp
  ): authorizer_otps_aggregate!
  "fetch data from the table: \"authorizer_otps\" using primary key columns"
  authorizer_otps_by_pk(id: bpchar!): authorizer_otps
  "fetch data from the table: \"authorizer_sessions\""
  authorizer_sessions(
    "distinct select on columns"
    distinct_on: [authorizer_sessions_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_sessions_order_by!],
    "filter the rows returned"
    where: authorizer_sessions_bool_exp
  ): [authorizer_sessions!]!
  "fetch aggregated fields from the table: \"authorizer_sessions\""
  authorizer_sessions_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_sessions_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_sessions_order_by!],
    "filter the rows returned"
    where: authorizer_sessions_bool_exp
  ): authorizer_sessions_aggregate!
  "fetch data from the table: \"authorizer_sessions\" using primary key columns"
  authorizer_sessions_by_pk(id: bpchar!): authorizer_sessions
  "fetch data from the table: \"authorizer_users\""
  authorizer_users(
    "distinct select on columns"
    distinct_on: [authorizer_users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_users_order_by!],
    "filter the rows returned"
    where: authorizer_users_bool_exp
  ): [authorizer_users!]!
  "fetch aggregated fields from the table: \"authorizer_users\""
  authorizer_users_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_users_order_by!],
    "filter the rows returned"
    where: authorizer_users_bool_exp
  ): authorizer_users_aggregate!
  "fetch data from the table: \"authorizer_users\" using primary key columns"
  authorizer_users_by_pk(id: bpchar!): authorizer_users
  "fetch data from the table: \"authorizer_verification_requests\""
  authorizer_verification_requests(
    "distinct select on columns"
    distinct_on: [authorizer_verification_requests_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_verification_requests_order_by!],
    "filter the rows returned"
    where: authorizer_verification_requests_bool_exp
  ): [authorizer_verification_requests!]!
  "fetch aggregated fields from the table: \"authorizer_verification_requests\""
  authorizer_verification_requests_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_verification_requests_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_verification_requests_order_by!],
    "filter the rows returned"
    where: authorizer_verification_requests_bool_exp
  ): authorizer_verification_requests_aggregate!
  "fetch data from the table: \"authorizer_verification_requests\" using primary key columns"
  authorizer_verification_requests_by_pk(id: bpchar!): authorizer_verification_requests
  "fetch data from the table: \"authorizer_webhook_logs\""
  authorizer_webhook_logs(
    "distinct select on columns"
    distinct_on: [authorizer_webhook_logs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhook_logs_order_by!],
    "filter the rows returned"
    where: authorizer_webhook_logs_bool_exp
  ): [authorizer_webhook_logs!]!
  "fetch aggregated fields from the table: \"authorizer_webhook_logs\""
  authorizer_webhook_logs_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_webhook_logs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhook_logs_order_by!],
    "filter the rows returned"
    where: authorizer_webhook_logs_bool_exp
  ): authorizer_webhook_logs_aggregate!
  "fetch data from the table: \"authorizer_webhook_logs\" using primary key columns"
  authorizer_webhook_logs_by_pk(id: bpchar!): authorizer_webhook_logs
  "fetch data from the table: \"authorizer_webhooks\""
  authorizer_webhooks(
    "distinct select on columns"
    distinct_on: [authorizer_webhooks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhooks_order_by!],
    "filter the rows returned"
    where: authorizer_webhooks_bool_exp
  ): [authorizer_webhooks!]!
  "fetch aggregated fields from the table: \"authorizer_webhooks\""
  authorizer_webhooks_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_webhooks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhooks_order_by!],
    "filter the rows returned"
    where: authorizer_webhooks_bool_exp
  ): authorizer_webhooks_aggregate!
  "fetch data from the table: \"authorizer_webhooks\" using primary key columns"
  authorizer_webhooks_by_pk(id: bpchar!): authorizer_webhooks
  "fetch data from the table: \"OrganizationClients\" using primary key columns"
  client(id: uuid!): OrganizationClients
  "fetch data from the table: \"OrganizationClients\""
  clients(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): [OrganizationClients!]!
  "fetch aggregated fields from the table: \"OrganizationClients\""
  clientsAggregate(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): OrganizationClients_aggregate!
  "fetch data from the table: \"Invoices\" using primary key columns"
  invoice(id: uuid!): Invoices
  "fetch data from the table: \"InvoiceSections\" using primary key columns"
  invoiceSection(id: uuid!): InvoiceSections
  "fetch data from the table: \"InvoiceSectionItems\" using primary key columns"
  invoiceSectionItem(id: uuid!): InvoiceSectionItems
  "fetch data from the table: \"InvoiceSectionItems\""
  invoiceSectionItems(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): [InvoiceSectionItems!]!
  "fetch aggregated fields from the table: \"InvoiceSectionItems\""
  invoiceSectionItemsAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): InvoiceSectionItems_aggregate!
  "fetch data from the table: \"InvoiceSections\""
  invoiceSections(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "fetch aggregated fields from the table: \"InvoiceSections\""
  invoiceSectionsAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): InvoiceSections_aggregate!
  "fetch data from the table: \"InvoiceStatuses\" using primary key columns"
  invoiceStatus(value: String!): InvoiceStatuses
  "fetch data from the table: \"InvoiceStatuses\""
  invoiceStatuses(
    "distinct select on columns"
    distinct_on: [InvoiceStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceStatuses_order_by!],
    "filter the rows returned"
    where: InvoiceStatuses_bool_exp
  ): [InvoiceStatuses!]!
  "fetch aggregated fields from the table: \"InvoiceStatuses\""
  invoiceStatusesAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceStatuses_order_by!],
    "filter the rows returned"
    where: InvoiceStatuses_bool_exp
  ): InvoiceStatuses_aggregate!
  "fetch data from the table: \"Invoices\""
  invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "fetch aggregated fields from the table: \"Invoices\""
  invoicesAggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  "fetch data from the table: \"Organizations\" using primary key columns"
  organization(id: uuid!): Organizations
  "fetch data from the table: \"Organizations\""
  organizations(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): [Organizations!]!
  "fetch aggregated fields from the table: \"Organizations\""
  organizationsAggreate(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): Organizations_aggregate!
  "fetch data from the table: \"Quotations\" using primary key columns"
  quotation(id: uuid!): Quotations
  "fetch data from the table: \"QuotationSections\" using primary key columns"
  quotationSection(id: uuid!): QuotationSections
  "fetch data from the table: \"QuotationSectionItems\" using primary key columns"
  quotationSectionItem(id: uuid!): QuotationSectionItems
  "fetch data from the table: \"QuotationSectionItems\""
  quotationSectionItems(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): [QuotationSectionItems!]!
  "fetch aggregated fields from the table: \"QuotationSectionItems\""
  quotationSectionItemsAggregate(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): QuotationSectionItems_aggregate!
  "fetch data from the table: \"QuotationSections\""
  quotationSections(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "fetch aggregated fields from the table: \"QuotationSections\""
  quotationSectionsAggregate(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): QuotationSections_aggregate!
  "fetch data from the table: \"QuotationStatuses\" using primary key columns"
  quotationStatus(value: String!): QuotationStatuses
  "fetch data from the table: \"QuotationStatuses\""
  quotationStatuses(
    "distinct select on columns"
    distinct_on: [QuotationStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationStatuses_order_by!],
    "filter the rows returned"
    where: QuotationStatuses_bool_exp
  ): [QuotationStatuses!]!
  "fetch aggregated fields from the table: \"QuotationStatuses\""
  quotationStatusesAggregate(
    "distinct select on columns"
    distinct_on: [QuotationStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationStatuses_order_by!],
    "filter the rows returned"
    where: QuotationStatuses_bool_exp
  ): QuotationStatuses_aggregate!
  "fetch data from the table: \"Quotations\""
  quotations(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "fetch aggregated fields from the table: \"Quotations\""
  quotationsAggregate(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): Quotations_aggregate!
  "fetch data from the table: \"Roles\" using primary key columns"
  role(value: String!): Roles
  "fetch data from the table: \"Roles\""
  roles(
    "distinct select on columns"
    distinct_on: [Roles_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Roles_order_by!],
    "filter the rows returned"
    where: Roles_bool_exp
  ): [Roles!]!
  "fetch aggregated fields from the table: \"Roles\""
  rolesAggregate(
    "distinct select on columns"
    distinct_on: [Roles_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Roles_order_by!],
    "filter the rows returned"
    where: Roles_bool_exp
  ): Roles_aggregate!
  "fetch data from the table: \"Stocks\" using primary key columns"
  stock(id: uuid!): Stocks
  "fetch data from the table: \"Stocks\""
  stocks(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): [Stocks!]!
  "fetch aggregated fields from the table: \"Stocks\""
  stocksAggregate(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): Stocks_aggregate!
}

type subscription_root {
  "fetch data from the table: \"InvoiceQuotationCategories\""
  InvoiceQuotationCategories(
    "distinct select on columns"
    distinct_on: [InvoiceQuotationCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceQuotationCategories_order_by!],
    "filter the rows returned"
    where: InvoiceQuotationCategories_bool_exp
  ): [InvoiceQuotationCategories!]!
  "fetch aggregated fields from the table: \"InvoiceQuotationCategories\""
  InvoiceQuotationCategories_aggregate(
    "distinct select on columns"
    distinct_on: [InvoiceQuotationCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceQuotationCategories_order_by!],
    "filter the rows returned"
    where: InvoiceQuotationCategories_bool_exp
  ): InvoiceQuotationCategories_aggregate!
  "fetch data from the table: \"InvoiceQuotationCategories\" using primary key columns"
  InvoiceQuotationCategories_by_pk(id: uuid!): InvoiceQuotationCategories
  "fetch data from the table in a streaming manner: \"InvoiceQuotationCategories\""
  InvoiceQuotationCategories_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [InvoiceQuotationCategories_stream_cursor_input]!,
    "filter the rows returned"
    where: InvoiceQuotationCategories_bool_exp
  ): [InvoiceQuotationCategories!]!
  "fetch data from the table: \"StockCategories\""
  StockCategories(
    "distinct select on columns"
    distinct_on: [StockCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [StockCategories_order_by!],
    "filter the rows returned"
    where: StockCategories_bool_exp
  ): [StockCategories!]!
  "fetch aggregated fields from the table: \"StockCategories\""
  StockCategories_aggregate(
    "distinct select on columns"
    distinct_on: [StockCategories_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [StockCategories_order_by!],
    "filter the rows returned"
    where: StockCategories_bool_exp
  ): StockCategories_aggregate!
  "fetch data from the table: \"StockCategories\" using primary key columns"
  StockCategories_by_pk(id: uuid!): StockCategories
  "fetch data from the table in a streaming manner: \"StockCategories\""
  StockCategories_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [StockCategories_stream_cursor_input]!,
    "filter the rows returned"
    where: StockCategories_bool_exp
  ): [StockCategories!]!
  "fetch data from the table: \"Units\""
  Units(
    "distinct select on columns"
    distinct_on: [Units_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Units_order_by!],
    "filter the rows returned"
    where: Units_bool_exp
  ): [Units!]!
  "fetch aggregated fields from the table: \"Units\""
  Units_aggregate(
    "distinct select on columns"
    distinct_on: [Units_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Units_order_by!],
    "filter the rows returned"
    where: Units_bool_exp
  ): Units_aggregate!
  "fetch data from the table: \"Units\" using primary key columns"
  Units_by_pk(value: String!): Units
  "fetch data from the table in a streaming manner: \"Units\""
  Units_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Units_stream_cursor_input]!,
    "filter the rows returned"
    where: Units_bool_exp
  ): [Units!]!
  "fetch data from the table: \"authorizer_email_templates\""
  authorizer_email_templates(
    "distinct select on columns"
    distinct_on: [authorizer_email_templates_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_email_templates_order_by!],
    "filter the rows returned"
    where: authorizer_email_templates_bool_exp
  ): [authorizer_email_templates!]!
  "fetch aggregated fields from the table: \"authorizer_email_templates\""
  authorizer_email_templates_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_email_templates_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_email_templates_order_by!],
    "filter the rows returned"
    where: authorizer_email_templates_bool_exp
  ): authorizer_email_templates_aggregate!
  "fetch data from the table: \"authorizer_email_templates\" using primary key columns"
  authorizer_email_templates_by_pk(id: bpchar!): authorizer_email_templates
  "fetch data from the table in a streaming manner: \"authorizer_email_templates\""
  authorizer_email_templates_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_email_templates_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_email_templates_bool_exp
  ): [authorizer_email_templates!]!
  "fetch data from the table: \"authorizer_envs\""
  authorizer_envs(
    "distinct select on columns"
    distinct_on: [authorizer_envs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_envs_order_by!],
    "filter the rows returned"
    where: authorizer_envs_bool_exp
  ): [authorizer_envs!]!
  "fetch aggregated fields from the table: \"authorizer_envs\""
  authorizer_envs_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_envs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_envs_order_by!],
    "filter the rows returned"
    where: authorizer_envs_bool_exp
  ): authorizer_envs_aggregate!
  "fetch data from the table: \"authorizer_envs\" using primary key columns"
  authorizer_envs_by_pk(id: bpchar!): authorizer_envs
  "fetch data from the table in a streaming manner: \"authorizer_envs\""
  authorizer_envs_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_envs_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_envs_bool_exp
  ): [authorizer_envs!]!
  "fetch data from the table: \"authorizer_otps\""
  authorizer_otps(
    "distinct select on columns"
    distinct_on: [authorizer_otps_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_otps_order_by!],
    "filter the rows returned"
    where: authorizer_otps_bool_exp
  ): [authorizer_otps!]!
  "fetch aggregated fields from the table: \"authorizer_otps\""
  authorizer_otps_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_otps_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_otps_order_by!],
    "filter the rows returned"
    where: authorizer_otps_bool_exp
  ): authorizer_otps_aggregate!
  "fetch data from the table: \"authorizer_otps\" using primary key columns"
  authorizer_otps_by_pk(id: bpchar!): authorizer_otps
  "fetch data from the table in a streaming manner: \"authorizer_otps\""
  authorizer_otps_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_otps_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_otps_bool_exp
  ): [authorizer_otps!]!
  "fetch data from the table: \"authorizer_sessions\""
  authorizer_sessions(
    "distinct select on columns"
    distinct_on: [authorizer_sessions_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_sessions_order_by!],
    "filter the rows returned"
    where: authorizer_sessions_bool_exp
  ): [authorizer_sessions!]!
  "fetch aggregated fields from the table: \"authorizer_sessions\""
  authorizer_sessions_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_sessions_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_sessions_order_by!],
    "filter the rows returned"
    where: authorizer_sessions_bool_exp
  ): authorizer_sessions_aggregate!
  "fetch data from the table: \"authorizer_sessions\" using primary key columns"
  authorizer_sessions_by_pk(id: bpchar!): authorizer_sessions
  "fetch data from the table in a streaming manner: \"authorizer_sessions\""
  authorizer_sessions_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_sessions_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_sessions_bool_exp
  ): [authorizer_sessions!]!
  "fetch data from the table: \"authorizer_users\""
  authorizer_users(
    "distinct select on columns"
    distinct_on: [authorizer_users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_users_order_by!],
    "filter the rows returned"
    where: authorizer_users_bool_exp
  ): [authorizer_users!]!
  "fetch aggregated fields from the table: \"authorizer_users\""
  authorizer_users_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_users_order_by!],
    "filter the rows returned"
    where: authorizer_users_bool_exp
  ): authorizer_users_aggregate!
  "fetch data from the table: \"authorizer_users\" using primary key columns"
  authorizer_users_by_pk(id: bpchar!): authorizer_users
  "fetch data from the table in a streaming manner: \"authorizer_users\""
  authorizer_users_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_users_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_users_bool_exp
  ): [authorizer_users!]!
  "fetch data from the table: \"authorizer_verification_requests\""
  authorizer_verification_requests(
    "distinct select on columns"
    distinct_on: [authorizer_verification_requests_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_verification_requests_order_by!],
    "filter the rows returned"
    where: authorizer_verification_requests_bool_exp
  ): [authorizer_verification_requests!]!
  "fetch aggregated fields from the table: \"authorizer_verification_requests\""
  authorizer_verification_requests_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_verification_requests_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_verification_requests_order_by!],
    "filter the rows returned"
    where: authorizer_verification_requests_bool_exp
  ): authorizer_verification_requests_aggregate!
  "fetch data from the table: \"authorizer_verification_requests\" using primary key columns"
  authorizer_verification_requests_by_pk(id: bpchar!): authorizer_verification_requests
  "fetch data from the table in a streaming manner: \"authorizer_verification_requests\""
  authorizer_verification_requests_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_verification_requests_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_verification_requests_bool_exp
  ): [authorizer_verification_requests!]!
  "fetch data from the table: \"authorizer_webhook_logs\""
  authorizer_webhook_logs(
    "distinct select on columns"
    distinct_on: [authorizer_webhook_logs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhook_logs_order_by!],
    "filter the rows returned"
    where: authorizer_webhook_logs_bool_exp
  ): [authorizer_webhook_logs!]!
  "fetch aggregated fields from the table: \"authorizer_webhook_logs\""
  authorizer_webhook_logs_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_webhook_logs_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhook_logs_order_by!],
    "filter the rows returned"
    where: authorizer_webhook_logs_bool_exp
  ): authorizer_webhook_logs_aggregate!
  "fetch data from the table: \"authorizer_webhook_logs\" using primary key columns"
  authorizer_webhook_logs_by_pk(id: bpchar!): authorizer_webhook_logs
  "fetch data from the table in a streaming manner: \"authorizer_webhook_logs\""
  authorizer_webhook_logs_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_webhook_logs_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_webhook_logs_bool_exp
  ): [authorizer_webhook_logs!]!
  "fetch data from the table: \"authorizer_webhooks\""
  authorizer_webhooks(
    "distinct select on columns"
    distinct_on: [authorizer_webhooks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhooks_order_by!],
    "filter the rows returned"
    where: authorizer_webhooks_bool_exp
  ): [authorizer_webhooks!]!
  "fetch aggregated fields from the table: \"authorizer_webhooks\""
  authorizer_webhooks_aggregate(
    "distinct select on columns"
    distinct_on: [authorizer_webhooks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [authorizer_webhooks_order_by!],
    "filter the rows returned"
    where: authorizer_webhooks_bool_exp
  ): authorizer_webhooks_aggregate!
  "fetch data from the table: \"authorizer_webhooks\" using primary key columns"
  authorizer_webhooks_by_pk(id: bpchar!): authorizer_webhooks
  "fetch data from the table in a streaming manner: \"authorizer_webhooks\""
  authorizer_webhooks_stream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [authorizer_webhooks_stream_cursor_input]!,
    "filter the rows returned"
    where: authorizer_webhooks_bool_exp
  ): [authorizer_webhooks!]!
  "fetch data from the table: \"OrganizationClients\" using primary key columns"
  client(id: uuid!): OrganizationClients
  "fetch data from the table: \"OrganizationClients\""
  clients(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): [OrganizationClients!]!
  "fetch aggregated fields from the table: \"OrganizationClients\""
  clientsAggregate(
    "distinct select on columns"
    distinct_on: [OrganizationClients_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [OrganizationClients_order_by!],
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): OrganizationClients_aggregate!
  "fetch data from the table in a streaming manner: \"OrganizationClients\""
  clientsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [OrganizationClients_stream_cursor_input]!,
    "filter the rows returned"
    where: OrganizationClients_bool_exp
  ): [OrganizationClients!]!
  "fetch data from the table: \"Invoices\" using primary key columns"
  invoice(id: uuid!): Invoices
  "fetch data from the table: \"InvoiceSections\" using primary key columns"
  invoiceSection(id: uuid!): InvoiceSections
  "fetch data from the table: \"InvoiceSectionItems\" using primary key columns"
  invoiceSectionItem(id: uuid!): InvoiceSectionItems
  "fetch data from the table: \"InvoiceSectionItems\""
  invoiceSectionItems(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): [InvoiceSectionItems!]!
  "fetch aggregated fields from the table: \"InvoiceSectionItems\""
  invoiceSectionItemsAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSectionItems_order_by!],
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): InvoiceSectionItems_aggregate!
  "fetch data from the table in a streaming manner: \"InvoiceSectionItems\""
  invoiceSectionItemsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [InvoiceSectionItems_stream_cursor_input]!,
    "filter the rows returned"
    where: InvoiceSectionItems_bool_exp
  ): [InvoiceSectionItems!]!
  "fetch data from the table: \"InvoiceSections\""
  invoiceSections(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "fetch aggregated fields from the table: \"InvoiceSections\""
  invoiceSectionsAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceSections_order_by!],
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): InvoiceSections_aggregate!
  "fetch data from the table in a streaming manner: \"InvoiceSections\""
  invoiceSectionsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [InvoiceSections_stream_cursor_input]!,
    "filter the rows returned"
    where: InvoiceSections_bool_exp
  ): [InvoiceSections!]!
  "fetch data from the table: \"InvoiceStatuses\" using primary key columns"
  invoiceStatus(value: String!): InvoiceStatuses
  "fetch data from the table: \"InvoiceStatuses\""
  invoiceStatuses(
    "distinct select on columns"
    distinct_on: [InvoiceStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceStatuses_order_by!],
    "filter the rows returned"
    where: InvoiceStatuses_bool_exp
  ): [InvoiceStatuses!]!
  "fetch aggregated fields from the table: \"InvoiceStatuses\""
  invoiceStatusesAggregate(
    "distinct select on columns"
    distinct_on: [InvoiceStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [InvoiceStatuses_order_by!],
    "filter the rows returned"
    where: InvoiceStatuses_bool_exp
  ): InvoiceStatuses_aggregate!
  "fetch data from the table in a streaming manner: \"InvoiceStatuses\""
  invoiceStatusesStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [InvoiceStatuses_stream_cursor_input]!,
    "filter the rows returned"
    where: InvoiceStatuses_bool_exp
  ): [InvoiceStatuses!]!
  "fetch data from the table: \"Invoices\""
  invoices(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "fetch aggregated fields from the table: \"Invoices\""
  invoicesAggregate(
    "distinct select on columns"
    distinct_on: [Invoices_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Invoices_order_by!],
    "filter the rows returned"
    where: Invoices_bool_exp
  ): Invoices_aggregate!
  "fetch data from the table in a streaming manner: \"Invoices\""
  invoicesStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Invoices_stream_cursor_input]!,
    "filter the rows returned"
    where: Invoices_bool_exp
  ): [Invoices!]!
  "fetch data from the table: \"Organizations\" using primary key columns"
  organization(id: uuid!): Organizations
  "fetch data from the table: \"Organizations\""
  organizations(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): [Organizations!]!
  "fetch aggregated fields from the table: \"Organizations\""
  organizationsAggreate(
    "distinct select on columns"
    distinct_on: [Organizations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Organizations_order_by!],
    "filter the rows returned"
    where: Organizations_bool_exp
  ): Organizations_aggregate!
  "fetch data from the table in a streaming manner: \"Organizations\""
  organizationsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Organizations_stream_cursor_input]!,
    "filter the rows returned"
    where: Organizations_bool_exp
  ): [Organizations!]!
  "fetch data from the table: \"Quotations\" using primary key columns"
  quotation(id: uuid!): Quotations
  "fetch data from the table: \"QuotationSections\" using primary key columns"
  quotationSection(id: uuid!): QuotationSections
  "fetch data from the table: \"QuotationSectionItems\" using primary key columns"
  quotationSectionItem(id: uuid!): QuotationSectionItems
  "fetch data from the table: \"QuotationSectionItems\""
  quotationSectionItems(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): [QuotationSectionItems!]!
  "fetch aggregated fields from the table: \"QuotationSectionItems\""
  quotationSectionItemsAggregate(
    "distinct select on columns"
    distinct_on: [QuotationSectionItems_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSectionItems_order_by!],
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): QuotationSectionItems_aggregate!
  "fetch data from the table in a streaming manner: \"QuotationSectionItems\""
  quotationSectionItemsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [QuotationSectionItems_stream_cursor_input]!,
    "filter the rows returned"
    where: QuotationSectionItems_bool_exp
  ): [QuotationSectionItems!]!
  "fetch data from the table: \"QuotationSections\""
  quotationSections(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "fetch aggregated fields from the table: \"QuotationSections\""
  quotationSectionsAggregate(
    "distinct select on columns"
    distinct_on: [QuotationSections_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationSections_order_by!],
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): QuotationSections_aggregate!
  "fetch data from the table in a streaming manner: \"QuotationSections\""
  quotationSectionsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [QuotationSections_stream_cursor_input]!,
    "filter the rows returned"
    where: QuotationSections_bool_exp
  ): [QuotationSections!]!
  "fetch data from the table: \"QuotationStatuses\" using primary key columns"
  quotationStatus(value: String!): QuotationStatuses
  "fetch data from the table: \"QuotationStatuses\""
  quotationStatuses(
    "distinct select on columns"
    distinct_on: [QuotationStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationStatuses_order_by!],
    "filter the rows returned"
    where: QuotationStatuses_bool_exp
  ): [QuotationStatuses!]!
  "fetch aggregated fields from the table: \"QuotationStatuses\""
  quotationStatusesAggregate(
    "distinct select on columns"
    distinct_on: [QuotationStatuses_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [QuotationStatuses_order_by!],
    "filter the rows returned"
    where: QuotationStatuses_bool_exp
  ): QuotationStatuses_aggregate!
  "fetch data from the table in a streaming manner: \"QuotationStatuses\""
  quotationStatusesStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [QuotationStatuses_stream_cursor_input]!,
    "filter the rows returned"
    where: QuotationStatuses_bool_exp
  ): [QuotationStatuses!]!
  "fetch data from the table: \"Quotations\""
  quotations(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "fetch aggregated fields from the table: \"Quotations\""
  quotationsAggregate(
    "distinct select on columns"
    distinct_on: [Quotations_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Quotations_order_by!],
    "filter the rows returned"
    where: Quotations_bool_exp
  ): Quotations_aggregate!
  "fetch data from the table in a streaming manner: \"Quotations\""
  quotationsStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Quotations_stream_cursor_input]!,
    "filter the rows returned"
    where: Quotations_bool_exp
  ): [Quotations!]!
  "fetch data from the table: \"Roles\" using primary key columns"
  role(value: String!): Roles
  "fetch data from the table: \"Roles\""
  roles(
    "distinct select on columns"
    distinct_on: [Roles_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Roles_order_by!],
    "filter the rows returned"
    where: Roles_bool_exp
  ): [Roles!]!
  "fetch aggregated fields from the table: \"Roles\""
  rolesAggregate(
    "distinct select on columns"
    distinct_on: [Roles_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Roles_order_by!],
    "filter the rows returned"
    where: Roles_bool_exp
  ): Roles_aggregate!
  "fetch data from the table in a streaming manner: \"Roles\""
  rolesStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Roles_stream_cursor_input]!,
    "filter the rows returned"
    where: Roles_bool_exp
  ): [Roles!]!
  "fetch data from the table: \"Stocks\" using primary key columns"
  stock(id: uuid!): Stocks
  "fetch data from the table: \"Stocks\""
  stocks(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): [Stocks!]!
  "fetch aggregated fields from the table: \"Stocks\""
  stocksAggregate(
    "distinct select on columns"
    distinct_on: [Stocks_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [Stocks_order_by!],
    "filter the rows returned"
    where: Stocks_bool_exp
  ): Stocks_aggregate!
  "fetch data from the table in a streaming manner: \"Stocks\""
  stocksStream(
    "maximum number of rows returned in a single batch"
    batch_size: Int!,
    "cursor to stream the results returned by the query"
    cursor: [Stocks_stream_cursor_input]!,
    "filter the rows returned"
    where: Stocks_bool_exp
  ): [Stocks!]!
}

"unique or primary key constraints on table \"InvoiceQuotationCategories\""
enum InvoiceQuotationCategories_constraint {
  "unique or primary key constraint on columns \"id\""
  InvoiceQuotationCategories_pkey
}

"select columns of table \"InvoiceQuotationCategories\""
enum InvoiceQuotationCategories_select_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  organizationId
  "column name"
  updated_at
  "column name"
  value
}

"update columns of table \"InvoiceQuotationCategories\""
enum InvoiceQuotationCategories_update_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  organizationId
  "column name"
  updated_at
  "column name"
  value
}

"unique or primary key constraints on table \"InvoiceSectionItems\""
enum InvoiceSectionItems_constraint {
  "unique or primary key constraint on columns \"id\""
  InvoiceSectionItems_pkey
}

"select columns of table \"InvoiceSectionItems\""
enum InvoiceSectionItems_select_column {
  "column name"
  createdAt
  "column name"
  description
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  price
  "column name"
  quantity
  "column name"
  sectionId
  "column name"
  updatedAt
}

"update columns of table \"InvoiceSectionItems\""
enum InvoiceSectionItems_update_column {
  "column name"
  createdAt
  "column name"
  description
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  price
  "column name"
  quantity
  "column name"
  sectionId
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"InvoiceSections\""
enum InvoiceSections_constraint {
  "unique or primary key constraint on columns \"id\""
  InvoiceSections_pkey
}

"select columns of table \"InvoiceSections\""
enum InvoiceSections_select_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  invoiceId
  "column name"
  name
  "column name"
  organizationId
  "column name"
  unit
  "column name"
  updatedAt
}

"update columns of table \"InvoiceSections\""
enum InvoiceSections_update_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  invoiceId
  "column name"
  name
  "column name"
  organizationId
  "column name"
  unit
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"InvoiceStatuses\""
enum InvoiceStatuses_constraint {
  "unique or primary key constraint on columns \"value\""
  InvoiceStatuses_pkey
}

"select columns of table \"InvoiceStatuses\""
enum InvoiceStatuses_select_column {
  "column name"
  value
}

"update columns of table \"InvoiceStatuses\""
enum InvoiceStatuses_update_column {
  "column name"
  value
}

"unique or primary key constraints on table \"Invoices\""
enum Invoices_constraint {
  "unique or primary key constraint on columns \"id\""
  Invoices_pkey
}

"select columns of table \"Invoices\""
enum Invoices_select_column {
  "column name"
  amount
  "column name"
  clientId
  "column name"
  createdAt
  "column name"
  dueOn
  "column name"
  id
  "column name"
  number
  "column name"
  organizationId
  "column name"
  quotationId
  "column name"
  sent
  "column name"
  status
  "column name"
  updatedAt
  "column name"
  viewed
}

"select \"Invoices_aggregate_bool_exp_bool_and_arguments_columns\" columns of table \"Invoices\""
enum Invoices_select_column_Invoices_aggregate_bool_exp_bool_and_arguments_columns {
  "column name"
  sent
  "column name"
  viewed
}

"select \"Invoices_aggregate_bool_exp_bool_or_arguments_columns\" columns of table \"Invoices\""
enum Invoices_select_column_Invoices_aggregate_bool_exp_bool_or_arguments_columns {
  "column name"
  sent
  "column name"
  viewed
}

"update columns of table \"Invoices\""
enum Invoices_update_column {
  "column name"
  amount
  "column name"
  clientId
  "column name"
  createdAt
  "column name"
  dueOn
  "column name"
  id
  "column name"
  number
  "column name"
  organizationId
  "column name"
  quotationId
  "column name"
  sent
  "column name"
  status
  "column name"
  updatedAt
  "column name"
  viewed
}

"unique or primary key constraints on table \"OrganizationClients\""
enum OrganizationClients_constraint {
  "unique or primary key constraint on columns \"id\""
  Clients_pkey
  "unique or primary key constraint on columns \"email\", \"organizationId\""
  OrganizationClients_email_organizationId_key
}

"select columns of table \"OrganizationClients\""
enum OrganizationClients_select_column {
  "column name"
  city
  "column name"
  country
  "column name"
  createdAt
  "column name"
  email
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  phoneNumberLandLine
  "column name"
  phoneNumberMobile
  "column name"
  postalCode
  "column name"
  state
  "column name"
  street
  "column name"
  updatedAt
}

"update columns of table \"OrganizationClients\""
enum OrganizationClients_update_column {
  "column name"
  city
  "column name"
  country
  "column name"
  createdAt
  "column name"
  email
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  phoneNumberLandLine
  "column name"
  phoneNumberMobile
  "column name"
  postalCode
  "column name"
  state
  "column name"
  street
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"Organizations\""
enum Organizations_constraint {
  "unique or primary key constraint on columns \"email\""
  Organizations_email_key
  "unique or primary key constraint on columns \"id\""
  Organizations_pkey
  "unique or primary key constraint on columns \"userId\""
  Organizations_userId_key
}

"select columns of table \"Organizations\""
enum Organizations_select_column {
  "column name"
  city
  "column name"
  createdAt
  "column name"
  email
  "column name"
  id
  "column name"
  name
  "column name"
  phoneNumberLandLine
  "column name"
  phoneNumberMobile
  "column name"
  postalCode
  "column name"
  state
  "column name"
  street
  "column name"
  updatedAt
  "column name"
  userId
}

"update columns of table \"Organizations\""
enum Organizations_update_column {
  "column name"
  city
  "column name"
  createdAt
  "column name"
  email
  "column name"
  id
  "column name"
  name
  "column name"
  phoneNumberLandLine
  "column name"
  phoneNumberMobile
  "column name"
  postalCode
  "column name"
  state
  "column name"
  street
  "column name"
  updatedAt
  "column name"
  userId
}

"unique or primary key constraints on table \"QuotationSectionItems\""
enum QuotationSectionItems_constraint {
  "unique or primary key constraint on columns \"id\""
  QuotationSectionItems_pkey
}

"select columns of table \"QuotationSectionItems\""
enum QuotationSectionItems_select_column {
  "column name"
  createdAt
  "column name"
  description
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  price
  "column name"
  quantity
  "column name"
  sectionId
  "column name"
  updatedAt
}

"update columns of table \"QuotationSectionItems\""
enum QuotationSectionItems_update_column {
  "column name"
  createdAt
  "column name"
  description
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  price
  "column name"
  quantity
  "column name"
  sectionId
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"QuotationSections\""
enum QuotationSections_constraint {
  "unique or primary key constraint on columns \"id\""
  QuotationSections_pkey
}

"select columns of table \"QuotationSections\""
enum QuotationSections_select_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  quotationId
  "column name"
  unit
  "column name"
  updatedAt
}

"update columns of table \"QuotationSections\""
enum QuotationSections_update_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  quotationId
  "column name"
  unit
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"QuotationStatuses\""
enum QuotationStatuses_constraint {
  "unique or primary key constraint on columns \"value\""
  QuotationStatuses_pkey
}

"select columns of table \"QuotationStatuses\""
enum QuotationStatuses_select_column {
  "column name"
  value
}

"update columns of table \"QuotationStatuses\""
enum QuotationStatuses_update_column {
  "column name"
  value
}

"unique or primary key constraints on table \"Quotations\""
enum Quotations_constraint {
  "unique or primary key constraint on columns \"id\""
  Quotations_pkey
}

"select columns of table \"Quotations\""
enum Quotations_select_column {
  "column name"
  clientId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  number
  "column name"
  organizationId
  "column name"
  sent
  "column name"
  status
  "column name"
  updatedAt
  "column name"
  validUntil
  "column name"
  viewed
}

"select \"Quotations_aggregate_bool_exp_bool_and_arguments_columns\" columns of table \"Quotations\""
enum Quotations_select_column_Quotations_aggregate_bool_exp_bool_and_arguments_columns {
  "column name"
  sent
  "column name"
  viewed
}

"select \"Quotations_aggregate_bool_exp_bool_or_arguments_columns\" columns of table \"Quotations\""
enum Quotations_select_column_Quotations_aggregate_bool_exp_bool_or_arguments_columns {
  "column name"
  sent
  "column name"
  viewed
}

"update columns of table \"Quotations\""
enum Quotations_update_column {
  "column name"
  clientId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  number
  "column name"
  organizationId
  "column name"
  sent
  "column name"
  status
  "column name"
  updatedAt
  "column name"
  validUntil
  "column name"
  viewed
}

"unique or primary key constraints on table \"Roles\""
enum Roles_constraint {
  "unique or primary key constraint on columns \"value\""
  Roles_pkey
}

"select columns of table \"Roles\""
enum Roles_select_column {
  "column name"
  value
}

"update columns of table \"Roles\""
enum Roles_update_column {
  "column name"
  value
}

"unique or primary key constraints on table \"StockCategories\""
enum StockCategories_constraint {
  "unique or primary key constraint on columns \"id\""
  Categories_pkey
}

"select columns of table \"StockCategories\""
enum StockCategories_select_column {
  "column name"
  id
  "column name"
  organizationId
  "column name"
  value
}

"update columns of table \"StockCategories\""
enum StockCategories_update_column {
  "column name"
  id
  "column name"
  organizationId
  "column name"
  value
}

"unique or primary key constraints on table \"Stocks\""
enum Stocks_constraint {
  "unique or primary key constraint on columns \"id\""
  Stocks_pkey
}

"select columns of table \"Stocks\""
enum Stocks_select_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  pricePerUnit
  "column name"
  unit
  "column name"
  updatedAt
}

"update columns of table \"Stocks\""
enum Stocks_update_column {
  "column name"
  categoryId
  "column name"
  createdAt
  "column name"
  id
  "column name"
  name
  "column name"
  organizationId
  "column name"
  pricePerUnit
  "column name"
  unit
  "column name"
  updatedAt
}

"unique or primary key constraints on table \"Units\""
enum Units_constraint {
  "unique or primary key constraint on columns \"value\""
  Units_pkey
}

"select columns of table \"Units\""
enum Units_select_column {
  "column name"
  organizationId
  "column name"
  value
}

"update columns of table \"Units\""
enum Units_update_column {
  "column name"
  organizationId
  "column name"
  value
}

"unique or primary key constraints on table \"authorizer_email_templates\""
enum authorizer_email_templates_constraint {
  "unique or primary key constraint on columns \"event_name\""
  authorizer_email_templates_event_name_key
  "unique or primary key constraint on columns \"id\""
  authorizer_email_templates_pkey
}

"select columns of table \"authorizer_email_templates\""
enum authorizer_email_templates_select_column {
  "column name"
  created_at
  "column name"
  design
  "column name"
  event_name
  "column name"
  id
  "column name"
  key
  "column name"
  subject
  "column name"
  template
  "column name"
  updated_at
}

"update columns of table \"authorizer_email_templates\""
enum authorizer_email_templates_update_column {
  "column name"
  created_at
  "column name"
  design
  "column name"
  event_name
  "column name"
  id
  "column name"
  key
  "column name"
  subject
  "column name"
  template
  "column name"
  updated_at
}

"unique or primary key constraints on table \"authorizer_envs\""
enum authorizer_envs_constraint {
  "unique or primary key constraint on columns \"id\""
  authorizer_envs_pkey
}

"select columns of table \"authorizer_envs\""
enum authorizer_envs_select_column {
  "column name"
  created_at
  "column name"
  encryption_key
  "column name"
  env_data
  "column name"
  hash
  "column name"
  id
  "column name"
  key
  "column name"
  updated_at
}

"update columns of table \"authorizer_envs\""
enum authorizer_envs_update_column {
  "column name"
  created_at
  "column name"
  encryption_key
  "column name"
  env_data
  "column name"
  hash
  "column name"
  id
  "column name"
  key
  "column name"
  updated_at
}

"unique or primary key constraints on table \"authorizer_otps\""
enum authorizer_otps_constraint {
  "unique or primary key constraint on columns \"email\""
  authorizer_otps_email_key
  "unique or primary key constraint on columns \"id\""
  authorizer_otps_pkey
}

"select columns of table \"authorizer_otps\""
enum authorizer_otps_select_column {
  "column name"
  created_at
  "column name"
  email
  "column name"
  expires_at
  "column name"
  id
  "column name"
  key
  "column name"
  otp
  "column name"
  updated_at
}

"update columns of table \"authorizer_otps\""
enum authorizer_otps_update_column {
  "column name"
  created_at
  "column name"
  email
  "column name"
  expires_at
  "column name"
  id
  "column name"
  key
  "column name"
  otp
  "column name"
  updated_at
}

"unique or primary key constraints on table \"authorizer_sessions\""
enum authorizer_sessions_constraint {
  "unique or primary key constraint on columns \"id\""
  authorizer_sessions_pkey
}

"select columns of table \"authorizer_sessions\""
enum authorizer_sessions_select_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  ip
  "column name"
  key
  "column name"
  updated_at
  "column name"
  user_agent
  "column name"
  user_id
}

"update columns of table \"authorizer_sessions\""
enum authorizer_sessions_update_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  ip
  "column name"
  key
  "column name"
  updated_at
  "column name"
  user_agent
  "column name"
  user_id
}

"unique or primary key constraints on table \"authorizer_users\""
enum authorizer_users_constraint {
  "unique or primary key constraint on columns \"email\""
  authorizer_users_email_key
  "unique or primary key constraint on columns \"id\""
  authorizer_users_pkey
}

"select columns of table \"authorizer_users\""
enum authorizer_users_select_column {
  "column name"
  birthdate
  "column name"
  created_at
  "column name"
  email
  "column name"
  email_verified_at
  "column name"
  family_name
  "column name"
  gender
  "column name"
  given_name
  "column name"
  id
  "column name"
  is_multi_factor_auth_enabled
  "column name"
  key
  "column name"
  middle_name
  "column name"
  nickname
  "column name"
  password
  "column name"
  phone_number
  "column name"
  phone_number_verified_at
  "column name"
  picture
  "column name"
  revoked_timestamp
  "column name"
  roles
  "column name"
  signup_methods
  "column name"
  updated_at
}

"update columns of table \"authorizer_users\""
enum authorizer_users_update_column {
  "column name"
  birthdate
  "column name"
  created_at
  "column name"
  email
  "column name"
  email_verified_at
  "column name"
  family_name
  "column name"
  gender
  "column name"
  given_name
  "column name"
  id
  "column name"
  is_multi_factor_auth_enabled
  "column name"
  key
  "column name"
  middle_name
  "column name"
  nickname
  "column name"
  password
  "column name"
  phone_number
  "column name"
  phone_number_verified_at
  "column name"
  picture
  "column name"
  revoked_timestamp
  "column name"
  roles
  "column name"
  signup_methods
  "column name"
  updated_at
}

"unique or primary key constraints on table \"authorizer_verification_requests\""
enum authorizer_verification_requests_constraint {
  "unique or primary key constraint on columns \"id\""
  authorizer_verification_requests_pkey
  "unique or primary key constraint on columns \"email\", \"identifier\""
  idx_email_identifier
}

"select columns of table \"authorizer_verification_requests\""
enum authorizer_verification_requests_select_column {
  "column name"
  created_at
  "column name"
  email
  "column name"
  expires_at
  "column name"
  id
  "column name"
  identifier
  "column name"
  key
  "column name"
  nonce
  "column name"
  redirect_uri
  "column name"
  token
  "column name"
  updated_at
}

"update columns of table \"authorizer_verification_requests\""
enum authorizer_verification_requests_update_column {
  "column name"
  created_at
  "column name"
  email
  "column name"
  expires_at
  "column name"
  id
  "column name"
  identifier
  "column name"
  key
  "column name"
  nonce
  "column name"
  redirect_uri
  "column name"
  token
  "column name"
  updated_at
}

"unique or primary key constraints on table \"authorizer_webhook_logs\""
enum authorizer_webhook_logs_constraint {
  "unique or primary key constraint on columns \"id\""
  authorizer_webhook_logs_pkey
}

"select columns of table \"authorizer_webhook_logs\""
enum authorizer_webhook_logs_select_column {
  "column name"
  created_at
  "column name"
  http_status
  "column name"
  id
  "column name"
  key
  "column name"
  request
  "column name"
  response
  "column name"
  updated_at
  "column name"
  webhook_id
}

"update columns of table \"authorizer_webhook_logs\""
enum authorizer_webhook_logs_update_column {
  "column name"
  created_at
  "column name"
  http_status
  "column name"
  id
  "column name"
  key
  "column name"
  request
  "column name"
  response
  "column name"
  updated_at
  "column name"
  webhook_id
}

"unique or primary key constraints on table \"authorizer_webhooks\""
enum authorizer_webhooks_constraint {
  "unique or primary key constraint on columns \"event_name\""
  authorizer_webhooks_event_name_key
  "unique or primary key constraint on columns \"id\""
  authorizer_webhooks_pkey
}

"select columns of table \"authorizer_webhooks\""
enum authorizer_webhooks_select_column {
  "column name"
  created_at
  "column name"
  enabled
  "column name"
  end_point
  "column name"
  event_name
  "column name"
  headers
  "column name"
  id
  "column name"
  key
  "column name"
  updated_at
}

"update columns of table \"authorizer_webhooks\""
enum authorizer_webhooks_update_column {
  "column name"
  created_at
  "column name"
  enabled
  "column name"
  end_point
  "column name"
  event_name
  "column name"
  headers
  "column name"
  id
  "column name"
  key
  "column name"
  updated_at
}

"ordering argument of a cursor"
enum cursor_ordering {
  "ascending ordering of the cursor"
  ASC
  "descending ordering of the cursor"
  DESC
}

"column ordering options"
enum order_by {
  "in ascending order, nulls last"
  asc
  "in ascending order, nulls first"
  asc_nulls_first
  "in ascending order, nulls last"
  asc_nulls_last
  "in descending order, nulls first"
  desc
  "in descending order, nulls first"
  desc_nulls_first
  "in descending order, nulls last"
  desc_nulls_last
}

scalar bigint

scalar bpchar

scalar date

scalar numeric

scalar timestamp

scalar timestamptz

scalar uuid

"Boolean expression to compare columns of type \"Boolean\". All fields are combined with logical 'AND'."
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"Boolean expression to filter rows from the table \"InvoiceQuotationCategories\". All fields are combined with a logical 'AND'."
input InvoiceQuotationCategories_bool_exp {
  InvoiceSections: InvoiceSections_bool_exp
  InvoiceSections_aggregate: InvoiceSections_aggregate_bool_exp
  Organization: Organizations_bool_exp
  QuotationSections: QuotationSections_bool_exp
  QuotationSections_aggregate: QuotationSections_aggregate_bool_exp
  _and: [InvoiceQuotationCategories_bool_exp!]
  _not: InvoiceQuotationCategories_bool_exp
  _or: [InvoiceQuotationCategories_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: uuid_comparison_exp
  organizationId: uuid_comparison_exp
  updated_at: timestamptz_comparison_exp
  value: String_comparison_exp
}

"input type for inserting data into table \"InvoiceQuotationCategories\""
input InvoiceQuotationCategories_insert_input {
  InvoiceSections: InvoiceSections_arr_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  QuotationSections: QuotationSections_arr_rel_insert_input
  created_at: timestamptz
  id: uuid
  organizationId: uuid
  updated_at: timestamptz
  value: String
}

"input type for inserting object relation for remote table \"InvoiceQuotationCategories\""
input InvoiceQuotationCategories_obj_rel_insert_input {
  data: InvoiceQuotationCategories_insert_input!
  "upsert condition"
  on_conflict: InvoiceQuotationCategories_on_conflict
}

"on_conflict condition type for table \"InvoiceQuotationCategories\""
input InvoiceQuotationCategories_on_conflict {
  constraint: InvoiceQuotationCategories_constraint!
  update_columns: [InvoiceQuotationCategories_update_column!]! = []
  where: InvoiceQuotationCategories_bool_exp
}

"Ordering options when selecting data from \"InvoiceQuotationCategories\"."
input InvoiceQuotationCategories_order_by {
  InvoiceSections_aggregate: InvoiceSections_aggregate_order_by
  Organization: Organizations_order_by
  QuotationSections_aggregate: QuotationSections_aggregate_order_by
  created_at: order_by
  id: order_by
  organizationId: order_by
  updated_at: order_by
  value: order_by
}

"primary key columns input for table: InvoiceQuotationCategories"
input InvoiceQuotationCategories_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"InvoiceQuotationCategories\""
input InvoiceQuotationCategories_set_input {
  created_at: timestamptz
  id: uuid
  organizationId: uuid
  updated_at: timestamptz
  value: String
}

"Streaming cursor of the table \"InvoiceQuotationCategories\""
input InvoiceQuotationCategories_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: InvoiceQuotationCategories_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input InvoiceQuotationCategories_stream_cursor_value_input {
  created_at: timestamptz
  id: uuid
  organizationId: uuid
  updated_at: timestamptz
  value: String
}

input InvoiceQuotationCategories_updates {
  "sets the columns of the filtered rows to the given values"
  _set: InvoiceQuotationCategories_set_input
  "filter the rows which have to be updated"
  where: InvoiceQuotationCategories_bool_exp!
}

input InvoiceSectionItems_aggregate_bool_exp {
  count: InvoiceSectionItems_aggregate_bool_exp_count
}

input InvoiceSectionItems_aggregate_bool_exp_count {
  arguments: [InvoiceSectionItems_select_column!]
  distinct: Boolean
  filter: InvoiceSectionItems_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"InvoiceSectionItems\""
input InvoiceSectionItems_aggregate_order_by {
  avg: InvoiceSectionItems_avg_order_by
  count: order_by
  max: InvoiceSectionItems_max_order_by
  min: InvoiceSectionItems_min_order_by
  stddev: InvoiceSectionItems_stddev_order_by
  stddev_pop: InvoiceSectionItems_stddev_pop_order_by
  stddev_samp: InvoiceSectionItems_stddev_samp_order_by
  sum: InvoiceSectionItems_sum_order_by
  var_pop: InvoiceSectionItems_var_pop_order_by
  var_samp: InvoiceSectionItems_var_samp_order_by
  variance: InvoiceSectionItems_variance_order_by
}

"input type for inserting array relation for remote table \"InvoiceSectionItems\""
input InvoiceSectionItems_arr_rel_insert_input {
  data: [InvoiceSectionItems_insert_input!]!
  "upsert condition"
  on_conflict: InvoiceSectionItems_on_conflict
}

"order by avg() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_avg_order_by {
  price: order_by
  quantity: order_by
}

"Boolean expression to filter rows from the table \"InvoiceSectionItems\". All fields are combined with a logical 'AND'."
input InvoiceSectionItems_bool_exp {
  InvoiceSection: InvoiceSections_bool_exp
  Organization: Organizations_bool_exp
  _and: [InvoiceSectionItems_bool_exp!]
  _not: InvoiceSectionItems_bool_exp
  _or: [InvoiceSectionItems_bool_exp!]
  createdAt: timestamptz_comparison_exp
  description: String_comparison_exp
  id: uuid_comparison_exp
  name: String_comparison_exp
  organizationId: uuid_comparison_exp
  price: numeric_comparison_exp
  quantity: Int_comparison_exp
  sectionId: uuid_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for incrementing numeric columns in table \"InvoiceSectionItems\""
input InvoiceSectionItems_inc_input {
  price: numeric
  quantity: Int
}

"input type for inserting data into table \"InvoiceSectionItems\""
input InvoiceSectionItems_insert_input {
  InvoiceSection: InvoiceSections_obj_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by max() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_max_order_by {
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_min_order_by {
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"on_conflict condition type for table \"InvoiceSectionItems\""
input InvoiceSectionItems_on_conflict {
  constraint: InvoiceSectionItems_constraint!
  update_columns: [InvoiceSectionItems_update_column!]! = []
  where: InvoiceSectionItems_bool_exp
}

"Ordering options when selecting data from \"InvoiceSectionItems\"."
input InvoiceSectionItems_order_by {
  InvoiceSection: InvoiceSections_order_by
  Organization: Organizations_order_by
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"primary key columns input for table: InvoiceSectionItems"
input InvoiceSectionItems_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"InvoiceSectionItems\""
input InvoiceSectionItems_set_input {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by stddev() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_stddev_order_by {
  price: order_by
  quantity: order_by
}

"order by stddev_pop() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_stddev_pop_order_by {
  price: order_by
  quantity: order_by
}

"order by stddev_samp() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_stddev_samp_order_by {
  price: order_by
  quantity: order_by
}

"Streaming cursor of the table \"InvoiceSectionItems\""
input InvoiceSectionItems_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: InvoiceSectionItems_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input InvoiceSectionItems_stream_cursor_value_input {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by sum() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_sum_order_by {
  price: order_by
  quantity: order_by
}

input InvoiceSectionItems_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: InvoiceSectionItems_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: InvoiceSectionItems_set_input
  "filter the rows which have to be updated"
  where: InvoiceSectionItems_bool_exp!
}

"order by var_pop() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_var_pop_order_by {
  price: order_by
  quantity: order_by
}

"order by var_samp() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_var_samp_order_by {
  price: order_by
  quantity: order_by
}

"order by variance() on columns of table \"InvoiceSectionItems\""
input InvoiceSectionItems_variance_order_by {
  price: order_by
  quantity: order_by
}

input InvoiceSections_aggregate_bool_exp {
  count: InvoiceSections_aggregate_bool_exp_count
}

input InvoiceSections_aggregate_bool_exp_count {
  arguments: [InvoiceSections_select_column!]
  distinct: Boolean
  filter: InvoiceSections_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"InvoiceSections\""
input InvoiceSections_aggregate_order_by {
  count: order_by
  max: InvoiceSections_max_order_by
  min: InvoiceSections_min_order_by
}

"input type for inserting array relation for remote table \"InvoiceSections\""
input InvoiceSections_arr_rel_insert_input {
  data: [InvoiceSections_insert_input!]!
  "upsert condition"
  on_conflict: InvoiceSections_on_conflict
}

"Boolean expression to filter rows from the table \"InvoiceSections\". All fields are combined with a logical 'AND'."
input InvoiceSections_bool_exp {
  Category: InvoiceQuotationCategories_bool_exp
  Invoice: Invoices_bool_exp
  InvoiceSectionItems: InvoiceSectionItems_bool_exp
  InvoiceSectionItems_aggregate: InvoiceSectionItems_aggregate_bool_exp
  Organization: Organizations_bool_exp
  Unit: Units_bool_exp
  _and: [InvoiceSections_bool_exp!]
  _not: InvoiceSections_bool_exp
  _or: [InvoiceSections_bool_exp!]
  categoryId: uuid_comparison_exp
  createdAt: timestamptz_comparison_exp
  id: uuid_comparison_exp
  invoiceId: uuid_comparison_exp
  name: bpchar_comparison_exp
  organizationId: uuid_comparison_exp
  unit: String_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for inserting data into table \"InvoiceSections\""
input InvoiceSections_insert_input {
  Category: InvoiceQuotationCategories_obj_rel_insert_input
  Invoice: Invoices_obj_rel_insert_input
  InvoiceSectionItems: InvoiceSectionItems_arr_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  Unit: Units_obj_rel_insert_input
  categoryId: uuid
  createdAt: timestamptz
  id: uuid
  invoiceId: uuid
  name: bpchar
  organizationId: uuid
  unit: String
  updatedAt: timestamptz
}

"order by max() on columns of table \"InvoiceSections\""
input InvoiceSections_max_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  invoiceId: order_by
  name: order_by
  organizationId: order_by
  unit: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"InvoiceSections\""
input InvoiceSections_min_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  invoiceId: order_by
  name: order_by
  organizationId: order_by
  unit: order_by
  updatedAt: order_by
}

"input type for inserting object relation for remote table \"InvoiceSections\""
input InvoiceSections_obj_rel_insert_input {
  data: InvoiceSections_insert_input!
  "upsert condition"
  on_conflict: InvoiceSections_on_conflict
}

"on_conflict condition type for table \"InvoiceSections\""
input InvoiceSections_on_conflict {
  constraint: InvoiceSections_constraint!
  update_columns: [InvoiceSections_update_column!]! = []
  where: InvoiceSections_bool_exp
}

"Ordering options when selecting data from \"InvoiceSections\"."
input InvoiceSections_order_by {
  Category: InvoiceQuotationCategories_order_by
  Invoice: Invoices_order_by
  InvoiceSectionItems_aggregate: InvoiceSectionItems_aggregate_order_by
  Organization: Organizations_order_by
  Unit: Units_order_by
  categoryId: order_by
  createdAt: order_by
  id: order_by
  invoiceId: order_by
  name: order_by
  organizationId: order_by
  unit: order_by
  updatedAt: order_by
}

"primary key columns input for table: InvoiceSections"
input InvoiceSections_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"InvoiceSections\""
input InvoiceSections_set_input {
  categoryId: uuid
  createdAt: timestamptz
  id: uuid
  invoiceId: uuid
  name: bpchar
  organizationId: uuid
  unit: String
  updatedAt: timestamptz
}

"Streaming cursor of the table \"InvoiceSections\""
input InvoiceSections_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: InvoiceSections_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input InvoiceSections_stream_cursor_value_input {
  categoryId: uuid
  createdAt: timestamptz
  id: uuid
  invoiceId: uuid
  name: bpchar
  organizationId: uuid
  unit: String
  updatedAt: timestamptz
}

input InvoiceSections_updates {
  "sets the columns of the filtered rows to the given values"
  _set: InvoiceSections_set_input
  "filter the rows which have to be updated"
  where: InvoiceSections_bool_exp!
}

"Boolean expression to filter rows from the table \"InvoiceStatuses\". All fields are combined with a logical 'AND'."
input InvoiceStatuses_bool_exp {
  Invoices: Invoices_bool_exp
  Invoices_aggregate: Invoices_aggregate_bool_exp
  _and: [InvoiceStatuses_bool_exp!]
  _not: InvoiceStatuses_bool_exp
  _or: [InvoiceStatuses_bool_exp!]
  value: String_comparison_exp
}

"input type for inserting data into table \"InvoiceStatuses\""
input InvoiceStatuses_insert_input {
  Invoices: Invoices_arr_rel_insert_input
  value: String
}

"input type for inserting object relation for remote table \"InvoiceStatuses\""
input InvoiceStatuses_obj_rel_insert_input {
  data: InvoiceStatuses_insert_input!
  "upsert condition"
  on_conflict: InvoiceStatuses_on_conflict
}

"on_conflict condition type for table \"InvoiceStatuses\""
input InvoiceStatuses_on_conflict {
  constraint: InvoiceStatuses_constraint!
  update_columns: [InvoiceStatuses_update_column!]! = []
  where: InvoiceStatuses_bool_exp
}

"Ordering options when selecting data from \"InvoiceStatuses\"."
input InvoiceStatuses_order_by {
  Invoices_aggregate: Invoices_aggregate_order_by
  value: order_by
}

"primary key columns input for table: InvoiceStatuses"
input InvoiceStatuses_pk_columns_input {
  value: String!
}

"input type for updating data in table \"InvoiceStatuses\""
input InvoiceStatuses_set_input {
  value: String
}

"Streaming cursor of the table \"InvoiceStatuses\""
input InvoiceStatuses_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: InvoiceStatuses_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input InvoiceStatuses_stream_cursor_value_input {
  value: String
}

input InvoiceStatuses_updates {
  "sets the columns of the filtered rows to the given values"
  _set: InvoiceStatuses_set_input
  "filter the rows which have to be updated"
  where: InvoiceStatuses_bool_exp!
}

input Invoices_aggregate_bool_exp {
  bool_and: Invoices_aggregate_bool_exp_bool_and
  bool_or: Invoices_aggregate_bool_exp_bool_or
  count: Invoices_aggregate_bool_exp_count
}

input Invoices_aggregate_bool_exp_bool_and {
  arguments: Invoices_select_column_Invoices_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: Invoices_bool_exp
  predicate: Boolean_comparison_exp!
}

input Invoices_aggregate_bool_exp_bool_or {
  arguments: Invoices_select_column_Invoices_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: Invoices_bool_exp
  predicate: Boolean_comparison_exp!
}

input Invoices_aggregate_bool_exp_count {
  arguments: [Invoices_select_column!]
  distinct: Boolean
  filter: Invoices_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"Invoices\""
input Invoices_aggregate_order_by {
  avg: Invoices_avg_order_by
  count: order_by
  max: Invoices_max_order_by
  min: Invoices_min_order_by
  stddev: Invoices_stddev_order_by
  stddev_pop: Invoices_stddev_pop_order_by
  stddev_samp: Invoices_stddev_samp_order_by
  sum: Invoices_sum_order_by
  var_pop: Invoices_var_pop_order_by
  var_samp: Invoices_var_samp_order_by
  variance: Invoices_variance_order_by
}

"input type for inserting array relation for remote table \"Invoices\""
input Invoices_arr_rel_insert_input {
  data: [Invoices_insert_input!]!
  "upsert condition"
  on_conflict: Invoices_on_conflict
}

"order by avg() on columns of table \"Invoices\""
input Invoices_avg_order_by {
  amount: order_by
  number: order_by
}

"Boolean expression to filter rows from the table \"Invoices\". All fields are combined with a logical 'AND'."
input Invoices_bool_exp {
  Client: OrganizationClients_bool_exp
  InvoiceSections: InvoiceSections_bool_exp
  InvoiceSections_aggregate: InvoiceSections_aggregate_bool_exp
  InvoiceStatus: InvoiceStatuses_bool_exp
  Organization: Organizations_bool_exp
  Quotation: Quotations_bool_exp
  _and: [Invoices_bool_exp!]
  _not: Invoices_bool_exp
  _or: [Invoices_bool_exp!]
  amount: numeric_comparison_exp
  clientId: uuid_comparison_exp
  createdAt: timestamptz_comparison_exp
  dueOn: date_comparison_exp
  id: uuid_comparison_exp
  number: Int_comparison_exp
  organizationId: uuid_comparison_exp
  quotationId: uuid_comparison_exp
  sent: Boolean_comparison_exp
  status: String_comparison_exp
  updatedAt: timestamptz_comparison_exp
  viewed: Boolean_comparison_exp
}

"input type for incrementing numeric columns in table \"Invoices\""
input Invoices_inc_input {
  amount: numeric
  number: Int
}

"input type for inserting data into table \"Invoices\""
input Invoices_insert_input {
  Client: OrganizationClients_obj_rel_insert_input
  InvoiceSections: InvoiceSections_arr_rel_insert_input
  InvoiceStatus: InvoiceStatuses_obj_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  Quotation: Quotations_obj_rel_insert_input
  amount: numeric
  clientId: uuid
  createdAt: timestamptz
  dueOn: date
  id: uuid
  number: Int
  organizationId: uuid
  quotationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamptz
  viewed: Boolean
}

"order by max() on columns of table \"Invoices\""
input Invoices_max_order_by {
  amount: order_by
  clientId: order_by
  createdAt: order_by
  dueOn: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  quotationId: order_by
  status: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"Invoices\""
input Invoices_min_order_by {
  amount: order_by
  clientId: order_by
  createdAt: order_by
  dueOn: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  quotationId: order_by
  status: order_by
  updatedAt: order_by
}

"input type for inserting object relation for remote table \"Invoices\""
input Invoices_obj_rel_insert_input {
  data: Invoices_insert_input!
  "upsert condition"
  on_conflict: Invoices_on_conflict
}

"on_conflict condition type for table \"Invoices\""
input Invoices_on_conflict {
  constraint: Invoices_constraint!
  update_columns: [Invoices_update_column!]! = []
  where: Invoices_bool_exp
}

"Ordering options when selecting data from \"Invoices\"."
input Invoices_order_by {
  Client: OrganizationClients_order_by
  InvoiceSections_aggregate: InvoiceSections_aggregate_order_by
  InvoiceStatus: InvoiceStatuses_order_by
  Organization: Organizations_order_by
  Quotation: Quotations_order_by
  amount: order_by
  clientId: order_by
  createdAt: order_by
  dueOn: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  quotationId: order_by
  sent: order_by
  status: order_by
  updatedAt: order_by
  viewed: order_by
}

"primary key columns input for table: Invoices"
input Invoices_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"Invoices\""
input Invoices_set_input {
  amount: numeric
  clientId: uuid
  createdAt: timestamptz
  dueOn: date
  id: uuid
  number: Int
  organizationId: uuid
  quotationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamptz
  viewed: Boolean
}

"order by stddev() on columns of table \"Invoices\""
input Invoices_stddev_order_by {
  amount: order_by
  number: order_by
}

"order by stddev_pop() on columns of table \"Invoices\""
input Invoices_stddev_pop_order_by {
  amount: order_by
  number: order_by
}

"order by stddev_samp() on columns of table \"Invoices\""
input Invoices_stddev_samp_order_by {
  amount: order_by
  number: order_by
}

"Streaming cursor of the table \"Invoices\""
input Invoices_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Invoices_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Invoices_stream_cursor_value_input {
  amount: numeric
  clientId: uuid
  createdAt: timestamptz
  dueOn: date
  id: uuid
  number: Int
  organizationId: uuid
  quotationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamptz
  viewed: Boolean
}

"order by sum() on columns of table \"Invoices\""
input Invoices_sum_order_by {
  amount: order_by
  number: order_by
}

input Invoices_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: Invoices_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: Invoices_set_input
  "filter the rows which have to be updated"
  where: Invoices_bool_exp!
}

"order by var_pop() on columns of table \"Invoices\""
input Invoices_var_pop_order_by {
  amount: order_by
  number: order_by
}

"order by var_samp() on columns of table \"Invoices\""
input Invoices_var_samp_order_by {
  amount: order_by
  number: order_by
}

"order by variance() on columns of table \"Invoices\""
input Invoices_variance_order_by {
  amount: order_by
  number: order_by
}

input OrganizationClients_aggregate_bool_exp {
  count: OrganizationClients_aggregate_bool_exp_count
}

input OrganizationClients_aggregate_bool_exp_count {
  arguments: [OrganizationClients_select_column!]
  distinct: Boolean
  filter: OrganizationClients_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"OrganizationClients\""
input OrganizationClients_aggregate_order_by {
  count: order_by
  max: OrganizationClients_max_order_by
  min: OrganizationClients_min_order_by
}

"input type for inserting array relation for remote table \"OrganizationClients\""
input OrganizationClients_arr_rel_insert_input {
  data: [OrganizationClients_insert_input!]!
  "upsert condition"
  on_conflict: OrganizationClients_on_conflict
}

"Boolean expression to filter rows from the table \"OrganizationClients\". All fields are combined with a logical 'AND'."
input OrganizationClients_bool_exp {
  Invoices: Invoices_bool_exp
  Invoices_aggregate: Invoices_aggregate_bool_exp
  Organization: Organizations_bool_exp
  Quotations: Quotations_bool_exp
  Quotations_aggregate: Quotations_aggregate_bool_exp
  _and: [OrganizationClients_bool_exp!]
  _not: OrganizationClients_bool_exp
  _or: [OrganizationClients_bool_exp!]
  city: String_comparison_exp
  country: String_comparison_exp
  createdAt: timestamp_comparison_exp
  email: String_comparison_exp
  id: uuid_comparison_exp
  name: String_comparison_exp
  organizationId: uuid_comparison_exp
  phoneNumberLandLine: String_comparison_exp
  phoneNumberMobile: String_comparison_exp
  postalCode: String_comparison_exp
  state: String_comparison_exp
  street: String_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for inserting data into table \"OrganizationClients\""
input OrganizationClients_insert_input {
  Invoices: Invoices_arr_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  Quotations: Quotations_arr_rel_insert_input
  city: String
  country: String
  createdAt: timestamp
  email: String
  id: uuid
  name: String
  organizationId: uuid
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz
}

"order by max() on columns of table \"OrganizationClients\""
input OrganizationClients_max_order_by {
  city: order_by
  country: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"OrganizationClients\""
input OrganizationClients_min_order_by {
  city: order_by
  country: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
}

"input type for inserting object relation for remote table \"OrganizationClients\""
input OrganizationClients_obj_rel_insert_input {
  data: OrganizationClients_insert_input!
  "upsert condition"
  on_conflict: OrganizationClients_on_conflict
}

"on_conflict condition type for table \"OrganizationClients\""
input OrganizationClients_on_conflict {
  constraint: OrganizationClients_constraint!
  update_columns: [OrganizationClients_update_column!]! = []
  where: OrganizationClients_bool_exp
}

"Ordering options when selecting data from \"OrganizationClients\"."
input OrganizationClients_order_by {
  Invoices_aggregate: Invoices_aggregate_order_by
  Organization: Organizations_order_by
  Quotations_aggregate: Quotations_aggregate_order_by
  city: order_by
  country: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
}

"primary key columns input for table: OrganizationClients"
input OrganizationClients_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"OrganizationClients\""
input OrganizationClients_set_input {
  city: String
  country: String
  createdAt: timestamp
  email: String
  id: uuid
  name: String
  organizationId: uuid
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz
}

"Streaming cursor of the table \"OrganizationClients\""
input OrganizationClients_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: OrganizationClients_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input OrganizationClients_stream_cursor_value_input {
  city: String
  country: String
  createdAt: timestamp
  email: String
  id: uuid
  name: String
  organizationId: uuid
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamptz
}

input OrganizationClients_updates {
  "sets the columns of the filtered rows to the given values"
  _set: OrganizationClients_set_input
  "filter the rows which have to be updated"
  where: OrganizationClients_bool_exp!
}

input Organizations_aggregate_bool_exp {
  count: Organizations_aggregate_bool_exp_count
}

input Organizations_aggregate_bool_exp_count {
  arguments: [Organizations_select_column!]
  distinct: Boolean
  filter: Organizations_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"Organizations\""
input Organizations_aggregate_order_by {
  count: order_by
  max: Organizations_max_order_by
  min: Organizations_min_order_by
}

"input type for inserting array relation for remote table \"Organizations\""
input Organizations_arr_rel_insert_input {
  data: [Organizations_insert_input!]!
  "upsert condition"
  on_conflict: Organizations_on_conflict
}

"Boolean expression to filter rows from the table \"Organizations\". All fields are combined with a logical 'AND'."
input Organizations_bool_exp {
  Clients: OrganizationClients_bool_exp
  Clients_aggregate: OrganizationClients_aggregate_bool_exp
  Invoices: Invoices_bool_exp
  Invoices_aggregate: Invoices_aggregate_bool_exp
  Quotations: Quotations_bool_exp
  Quotations_aggregate: Quotations_aggregate_bool_exp
  Stocks: Stocks_bool_exp
  Stocks_aggregate: Stocks_aggregate_bool_exp
  _and: [Organizations_bool_exp!]
  _not: Organizations_bool_exp
  _or: [Organizations_bool_exp!]
  authorizer_user: authorizer_users_bool_exp
  city: String_comparison_exp
  createdAt: timestamp_comparison_exp
  email: String_comparison_exp
  id: uuid_comparison_exp
  name: bpchar_comparison_exp
  phoneNumberLandLine: String_comparison_exp
  phoneNumberMobile: String_comparison_exp
  postalCode: String_comparison_exp
  state: String_comparison_exp
  street: String_comparison_exp
  updatedAt: timestamp_comparison_exp
  userId: bpchar_comparison_exp
}

"input type for inserting data into table \"Organizations\""
input Organizations_insert_input {
  Clients: OrganizationClients_arr_rel_insert_input
  Invoices: Invoices_arr_rel_insert_input
  Quotations: Quotations_arr_rel_insert_input
  Stocks: Stocks_arr_rel_insert_input
  authorizer_user: authorizer_users_obj_rel_insert_input
  city: String
  createdAt: timestamp
  email: String
  id: uuid
  name: bpchar
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamp
  userId: bpchar
}

"order by max() on columns of table \"Organizations\""
input Organizations_max_order_by {
  city: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
  userId: order_by
}

"order by min() on columns of table \"Organizations\""
input Organizations_min_order_by {
  city: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
  userId: order_by
}

"input type for inserting object relation for remote table \"Organizations\""
input Organizations_obj_rel_insert_input {
  data: Organizations_insert_input!
  "upsert condition"
  on_conflict: Organizations_on_conflict
}

"on_conflict condition type for table \"Organizations\""
input Organizations_on_conflict {
  constraint: Organizations_constraint!
  update_columns: [Organizations_update_column!]! = []
  where: Organizations_bool_exp
}

"Ordering options when selecting data from \"Organizations\"."
input Organizations_order_by {
  Clients_aggregate: OrganizationClients_aggregate_order_by
  Invoices_aggregate: Invoices_aggregate_order_by
  Quotations_aggregate: Quotations_aggregate_order_by
  Stocks_aggregate: Stocks_aggregate_order_by
  authorizer_user: authorizer_users_order_by
  city: order_by
  createdAt: order_by
  email: order_by
  id: order_by
  name: order_by
  phoneNumberLandLine: order_by
  phoneNumberMobile: order_by
  postalCode: order_by
  state: order_by
  street: order_by
  updatedAt: order_by
  userId: order_by
}

"primary key columns input for table: Organizations"
input Organizations_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"Organizations\""
input Organizations_set_input {
  city: String
  createdAt: timestamp
  email: String
  id: uuid
  name: bpchar
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamp
  userId: bpchar
}

"Streaming cursor of the table \"Organizations\""
input Organizations_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Organizations_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Organizations_stream_cursor_value_input {
  city: String
  createdAt: timestamp
  email: String
  id: uuid
  name: bpchar
  phoneNumberLandLine: String
  phoneNumberMobile: String
  postalCode: String
  state: String
  street: String
  updatedAt: timestamp
  userId: bpchar
}

input Organizations_updates {
  "sets the columns of the filtered rows to the given values"
  _set: Organizations_set_input
  "filter the rows which have to be updated"
  where: Organizations_bool_exp!
}

input QuotationSectionItems_aggregate_bool_exp {
  count: QuotationSectionItems_aggregate_bool_exp_count
}

input QuotationSectionItems_aggregate_bool_exp_count {
  arguments: [QuotationSectionItems_select_column!]
  distinct: Boolean
  filter: QuotationSectionItems_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"QuotationSectionItems\""
input QuotationSectionItems_aggregate_order_by {
  avg: QuotationSectionItems_avg_order_by
  count: order_by
  max: QuotationSectionItems_max_order_by
  min: QuotationSectionItems_min_order_by
  stddev: QuotationSectionItems_stddev_order_by
  stddev_pop: QuotationSectionItems_stddev_pop_order_by
  stddev_samp: QuotationSectionItems_stddev_samp_order_by
  sum: QuotationSectionItems_sum_order_by
  var_pop: QuotationSectionItems_var_pop_order_by
  var_samp: QuotationSectionItems_var_samp_order_by
  variance: QuotationSectionItems_variance_order_by
}

"input type for inserting array relation for remote table \"QuotationSectionItems\""
input QuotationSectionItems_arr_rel_insert_input {
  data: [QuotationSectionItems_insert_input!]!
  "upsert condition"
  on_conflict: QuotationSectionItems_on_conflict
}

"order by avg() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_avg_order_by {
  price: order_by
  quantity: order_by
}

"Boolean expression to filter rows from the table \"QuotationSectionItems\". All fields are combined with a logical 'AND'."
input QuotationSectionItems_bool_exp {
  Organization: Organizations_bool_exp
  QuotationSection: QuotationSections_bool_exp
  _and: [QuotationSectionItems_bool_exp!]
  _not: QuotationSectionItems_bool_exp
  _or: [QuotationSectionItems_bool_exp!]
  createdAt: timestamptz_comparison_exp
  description: String_comparison_exp
  id: uuid_comparison_exp
  name: String_comparison_exp
  organizationId: uuid_comparison_exp
  price: numeric_comparison_exp
  quantity: Int_comparison_exp
  sectionId: uuid_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for incrementing numeric columns in table \"QuotationSectionItems\""
input QuotationSectionItems_inc_input {
  price: numeric
  quantity: Int
}

"input type for inserting data into table \"QuotationSectionItems\""
input QuotationSectionItems_insert_input {
  Organization: Organizations_obj_rel_insert_input
  QuotationSection: QuotationSections_obj_rel_insert_input
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by max() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_max_order_by {
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_min_order_by {
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"on_conflict condition type for table \"QuotationSectionItems\""
input QuotationSectionItems_on_conflict {
  constraint: QuotationSectionItems_constraint!
  update_columns: [QuotationSectionItems_update_column!]! = []
  where: QuotationSectionItems_bool_exp
}

"Ordering options when selecting data from \"QuotationSectionItems\"."
input QuotationSectionItems_order_by {
  Organization: Organizations_order_by
  QuotationSection: QuotationSections_order_by
  createdAt: order_by
  description: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  price: order_by
  quantity: order_by
  sectionId: order_by
  updatedAt: order_by
}

"primary key columns input for table: QuotationSectionItems"
input QuotationSectionItems_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"QuotationSectionItems\""
input QuotationSectionItems_set_input {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by stddev() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_stddev_order_by {
  price: order_by
  quantity: order_by
}

"order by stddev_pop() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_stddev_pop_order_by {
  price: order_by
  quantity: order_by
}

"order by stddev_samp() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_stddev_samp_order_by {
  price: order_by
  quantity: order_by
}

"Streaming cursor of the table \"QuotationSectionItems\""
input QuotationSectionItems_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: QuotationSectionItems_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input QuotationSectionItems_stream_cursor_value_input {
  createdAt: timestamptz
  description: String
  id: uuid
  name: String
  organizationId: uuid
  price: numeric
  quantity: Int
  sectionId: uuid
  updatedAt: timestamptz
}

"order by sum() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_sum_order_by {
  price: order_by
  quantity: order_by
}

input QuotationSectionItems_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: QuotationSectionItems_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: QuotationSectionItems_set_input
  "filter the rows which have to be updated"
  where: QuotationSectionItems_bool_exp!
}

"order by var_pop() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_var_pop_order_by {
  price: order_by
  quantity: order_by
}

"order by var_samp() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_var_samp_order_by {
  price: order_by
  quantity: order_by
}

"order by variance() on columns of table \"QuotationSectionItems\""
input QuotationSectionItems_variance_order_by {
  price: order_by
  quantity: order_by
}

input QuotationSections_aggregate_bool_exp {
  count: QuotationSections_aggregate_bool_exp_count
}

input QuotationSections_aggregate_bool_exp_count {
  arguments: [QuotationSections_select_column!]
  distinct: Boolean
  filter: QuotationSections_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"QuotationSections\""
input QuotationSections_aggregate_order_by {
  count: order_by
  max: QuotationSections_max_order_by
  min: QuotationSections_min_order_by
}

"input type for inserting array relation for remote table \"QuotationSections\""
input QuotationSections_arr_rel_insert_input {
  data: [QuotationSections_insert_input!]!
  "upsert condition"
  on_conflict: QuotationSections_on_conflict
}

"Boolean expression to filter rows from the table \"QuotationSections\". All fields are combined with a logical 'AND'."
input QuotationSections_bool_exp {
  Category: InvoiceQuotationCategories_bool_exp
  Organization: Organizations_bool_exp
  Quotation: Quotations_bool_exp
  QuotationSectionItems: QuotationSectionItems_bool_exp
  QuotationSectionItems_aggregate: QuotationSectionItems_aggregate_bool_exp
  Unit: Units_bool_exp
  _and: [QuotationSections_bool_exp!]
  _not: QuotationSections_bool_exp
  _or: [QuotationSections_bool_exp!]
  categoryId: uuid_comparison_exp
  createdAt: timestamp_comparison_exp
  id: uuid_comparison_exp
  name: String_comparison_exp
  organizationId: uuid_comparison_exp
  quotationId: uuid_comparison_exp
  unit: String_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for inserting data into table \"QuotationSections\""
input QuotationSections_insert_input {
  Category: InvoiceQuotationCategories_obj_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  Quotation: Quotations_obj_rel_insert_input
  QuotationSectionItems: QuotationSectionItems_arr_rel_insert_input
  Unit: Units_obj_rel_insert_input
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  quotationId: uuid
  unit: String
  updatedAt: timestamptz
}

"order by max() on columns of table \"QuotationSections\""
input QuotationSections_max_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  quotationId: order_by
  unit: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"QuotationSections\""
input QuotationSections_min_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  quotationId: order_by
  unit: order_by
  updatedAt: order_by
}

"input type for inserting object relation for remote table \"QuotationSections\""
input QuotationSections_obj_rel_insert_input {
  data: QuotationSections_insert_input!
  "upsert condition"
  on_conflict: QuotationSections_on_conflict
}

"on_conflict condition type for table \"QuotationSections\""
input QuotationSections_on_conflict {
  constraint: QuotationSections_constraint!
  update_columns: [QuotationSections_update_column!]! = []
  where: QuotationSections_bool_exp
}

"Ordering options when selecting data from \"QuotationSections\"."
input QuotationSections_order_by {
  Category: InvoiceQuotationCategories_order_by
  Organization: Organizations_order_by
  Quotation: Quotations_order_by
  QuotationSectionItems_aggregate: QuotationSectionItems_aggregate_order_by
  Unit: Units_order_by
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  quotationId: order_by
  unit: order_by
  updatedAt: order_by
}

"primary key columns input for table: QuotationSections"
input QuotationSections_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"QuotationSections\""
input QuotationSections_set_input {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  quotationId: uuid
  unit: String
  updatedAt: timestamptz
}

"Streaming cursor of the table \"QuotationSections\""
input QuotationSections_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: QuotationSections_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input QuotationSections_stream_cursor_value_input {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  quotationId: uuid
  unit: String
  updatedAt: timestamptz
}

input QuotationSections_updates {
  "sets the columns of the filtered rows to the given values"
  _set: QuotationSections_set_input
  "filter the rows which have to be updated"
  where: QuotationSections_bool_exp!
}

"Boolean expression to filter rows from the table \"QuotationStatuses\". All fields are combined with a logical 'AND'."
input QuotationStatuses_bool_exp {
  Quotations: Quotations_bool_exp
  Quotations_aggregate: Quotations_aggregate_bool_exp
  _and: [QuotationStatuses_bool_exp!]
  _not: QuotationStatuses_bool_exp
  _or: [QuotationStatuses_bool_exp!]
  value: String_comparison_exp
}

"input type for inserting data into table \"QuotationStatuses\""
input QuotationStatuses_insert_input {
  Quotations: Quotations_arr_rel_insert_input
  value: String
}

"input type for inserting object relation for remote table \"QuotationStatuses\""
input QuotationStatuses_obj_rel_insert_input {
  data: QuotationStatuses_insert_input!
  "upsert condition"
  on_conflict: QuotationStatuses_on_conflict
}

"on_conflict condition type for table \"QuotationStatuses\""
input QuotationStatuses_on_conflict {
  constraint: QuotationStatuses_constraint!
  update_columns: [QuotationStatuses_update_column!]! = []
  where: QuotationStatuses_bool_exp
}

"Ordering options when selecting data from \"QuotationStatuses\"."
input QuotationStatuses_order_by {
  Quotations_aggregate: Quotations_aggregate_order_by
  value: order_by
}

"primary key columns input for table: QuotationStatuses"
input QuotationStatuses_pk_columns_input {
  value: String!
}

"input type for updating data in table \"QuotationStatuses\""
input QuotationStatuses_set_input {
  value: String
}

"Streaming cursor of the table \"QuotationStatuses\""
input QuotationStatuses_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: QuotationStatuses_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input QuotationStatuses_stream_cursor_value_input {
  value: String
}

input QuotationStatuses_updates {
  "sets the columns of the filtered rows to the given values"
  _set: QuotationStatuses_set_input
  "filter the rows which have to be updated"
  where: QuotationStatuses_bool_exp!
}

input Quotations_aggregate_bool_exp {
  bool_and: Quotations_aggregate_bool_exp_bool_and
  bool_or: Quotations_aggregate_bool_exp_bool_or
  count: Quotations_aggregate_bool_exp_count
}

input Quotations_aggregate_bool_exp_bool_and {
  arguments: Quotations_select_column_Quotations_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: Quotations_bool_exp
  predicate: Boolean_comparison_exp!
}

input Quotations_aggregate_bool_exp_bool_or {
  arguments: Quotations_select_column_Quotations_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: Quotations_bool_exp
  predicate: Boolean_comparison_exp!
}

input Quotations_aggregate_bool_exp_count {
  arguments: [Quotations_select_column!]
  distinct: Boolean
  filter: Quotations_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"Quotations\""
input Quotations_aggregate_order_by {
  avg: Quotations_avg_order_by
  count: order_by
  max: Quotations_max_order_by
  min: Quotations_min_order_by
  stddev: Quotations_stddev_order_by
  stddev_pop: Quotations_stddev_pop_order_by
  stddev_samp: Quotations_stddev_samp_order_by
  sum: Quotations_sum_order_by
  var_pop: Quotations_var_pop_order_by
  var_samp: Quotations_var_samp_order_by
  variance: Quotations_variance_order_by
}

"input type for inserting array relation for remote table \"Quotations\""
input Quotations_arr_rel_insert_input {
  data: [Quotations_insert_input!]!
  "upsert condition"
  on_conflict: Quotations_on_conflict
}

"order by avg() on columns of table \"Quotations\""
input Quotations_avg_order_by {
  number: order_by
}

"Boolean expression to filter rows from the table \"Quotations\". All fields are combined with a logical 'AND'."
input Quotations_bool_exp {
  Client: OrganizationClients_bool_exp
  Invoices: Invoices_bool_exp
  Invoices_aggregate: Invoices_aggregate_bool_exp
  Organization: Organizations_bool_exp
  QuotationSections: QuotationSections_bool_exp
  QuotationSections_aggregate: QuotationSections_aggregate_bool_exp
  QuotationStatus: QuotationStatuses_bool_exp
  _and: [Quotations_bool_exp!]
  _not: Quotations_bool_exp
  _or: [Quotations_bool_exp!]
  clientId: uuid_comparison_exp
  createdAt: timestamp_comparison_exp
  id: uuid_comparison_exp
  number: Int_comparison_exp
  organizationId: uuid_comparison_exp
  sent: Boolean_comparison_exp
  status: String_comparison_exp
  updatedAt: timestamp_comparison_exp
  validUntil: date_comparison_exp
  viewed: Boolean_comparison_exp
}

"input type for incrementing numeric columns in table \"Quotations\""
input Quotations_inc_input {
  number: Int
}

"input type for inserting data into table \"Quotations\""
input Quotations_insert_input {
  Client: OrganizationClients_obj_rel_insert_input
  Invoices: Invoices_arr_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  QuotationSections: QuotationSections_arr_rel_insert_input
  QuotationStatus: QuotationStatuses_obj_rel_insert_input
  clientId: uuid
  createdAt: timestamp
  id: uuid
  number: Int
  organizationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamp
  validUntil: date
  viewed: Boolean
}

"order by max() on columns of table \"Quotations\""
input Quotations_max_order_by {
  clientId: order_by
  createdAt: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  status: order_by
  updatedAt: order_by
  validUntil: order_by
}

"order by min() on columns of table \"Quotations\""
input Quotations_min_order_by {
  clientId: order_by
  createdAt: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  status: order_by
  updatedAt: order_by
  validUntil: order_by
}

"input type for inserting object relation for remote table \"Quotations\""
input Quotations_obj_rel_insert_input {
  data: Quotations_insert_input!
  "upsert condition"
  on_conflict: Quotations_on_conflict
}

"on_conflict condition type for table \"Quotations\""
input Quotations_on_conflict {
  constraint: Quotations_constraint!
  update_columns: [Quotations_update_column!]! = []
  where: Quotations_bool_exp
}

"Ordering options when selecting data from \"Quotations\"."
input Quotations_order_by {
  Client: OrganizationClients_order_by
  Invoices_aggregate: Invoices_aggregate_order_by
  Organization: Organizations_order_by
  QuotationSections_aggregate: QuotationSections_aggregate_order_by
  QuotationStatus: QuotationStatuses_order_by
  clientId: order_by
  createdAt: order_by
  id: order_by
  number: order_by
  organizationId: order_by
  sent: order_by
  status: order_by
  updatedAt: order_by
  validUntil: order_by
  viewed: order_by
}

"primary key columns input for table: Quotations"
input Quotations_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"Quotations\""
input Quotations_set_input {
  clientId: uuid
  createdAt: timestamp
  id: uuid
  number: Int
  organizationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamp
  validUntil: date
  viewed: Boolean
}

"order by stddev() on columns of table \"Quotations\""
input Quotations_stddev_order_by {
  number: order_by
}

"order by stddev_pop() on columns of table \"Quotations\""
input Quotations_stddev_pop_order_by {
  number: order_by
}

"order by stddev_samp() on columns of table \"Quotations\""
input Quotations_stddev_samp_order_by {
  number: order_by
}

"Streaming cursor of the table \"Quotations\""
input Quotations_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Quotations_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Quotations_stream_cursor_value_input {
  clientId: uuid
  createdAt: timestamp
  id: uuid
  number: Int
  organizationId: uuid
  sent: Boolean
  status: String
  updatedAt: timestamp
  validUntil: date
  viewed: Boolean
}

"order by sum() on columns of table \"Quotations\""
input Quotations_sum_order_by {
  number: order_by
}

input Quotations_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: Quotations_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: Quotations_set_input
  "filter the rows which have to be updated"
  where: Quotations_bool_exp!
}

"order by var_pop() on columns of table \"Quotations\""
input Quotations_var_pop_order_by {
  number: order_by
}

"order by var_samp() on columns of table \"Quotations\""
input Quotations_var_samp_order_by {
  number: order_by
}

"order by variance() on columns of table \"Quotations\""
input Quotations_variance_order_by {
  number: order_by
}

"Boolean expression to filter rows from the table \"Roles\". All fields are combined with a logical 'AND'."
input Roles_bool_exp {
  _and: [Roles_bool_exp!]
  _not: Roles_bool_exp
  _or: [Roles_bool_exp!]
  value: String_comparison_exp
}

"input type for inserting data into table \"Roles\""
input Roles_insert_input {
  value: String
}

"on_conflict condition type for table \"Roles\""
input Roles_on_conflict {
  constraint: Roles_constraint!
  update_columns: [Roles_update_column!]! = []
  where: Roles_bool_exp
}

"Ordering options when selecting data from \"Roles\"."
input Roles_order_by {
  value: order_by
}

"primary key columns input for table: Roles"
input Roles_pk_columns_input {
  value: String!
}

"input type for updating data in table \"Roles\""
input Roles_set_input {
  value: String
}

"Streaming cursor of the table \"Roles\""
input Roles_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Roles_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Roles_stream_cursor_value_input {
  value: String
}

input Roles_updates {
  "sets the columns of the filtered rows to the given values"
  _set: Roles_set_input
  "filter the rows which have to be updated"
  where: Roles_bool_exp!
}

"Boolean expression to filter rows from the table \"StockCategories\". All fields are combined with a logical 'AND'."
input StockCategories_bool_exp {
  Organization: Organizations_bool_exp
  Stocks: Stocks_bool_exp
  Stocks_aggregate: Stocks_aggregate_bool_exp
  _and: [StockCategories_bool_exp!]
  _not: StockCategories_bool_exp
  _or: [StockCategories_bool_exp!]
  id: uuid_comparison_exp
  organizationId: uuid_comparison_exp
  value: String_comparison_exp
}

"input type for inserting data into table \"StockCategories\""
input StockCategories_insert_input {
  Organization: Organizations_obj_rel_insert_input
  Stocks: Stocks_arr_rel_insert_input
  id: uuid
  organizationId: uuid
  value: String
}

"input type for inserting object relation for remote table \"StockCategories\""
input StockCategories_obj_rel_insert_input {
  data: StockCategories_insert_input!
  "upsert condition"
  on_conflict: StockCategories_on_conflict
}

"on_conflict condition type for table \"StockCategories\""
input StockCategories_on_conflict {
  constraint: StockCategories_constraint!
  update_columns: [StockCategories_update_column!]! = []
  where: StockCategories_bool_exp
}

"Ordering options when selecting data from \"StockCategories\"."
input StockCategories_order_by {
  Organization: Organizations_order_by
  Stocks_aggregate: Stocks_aggregate_order_by
  id: order_by
  organizationId: order_by
  value: order_by
}

"primary key columns input for table: StockCategories"
input StockCategories_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"StockCategories\""
input StockCategories_set_input {
  id: uuid
  organizationId: uuid
  value: String
}

"Streaming cursor of the table \"StockCategories\""
input StockCategories_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: StockCategories_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input StockCategories_stream_cursor_value_input {
  id: uuid
  organizationId: uuid
  value: String
}

input StockCategories_updates {
  "sets the columns of the filtered rows to the given values"
  _set: StockCategories_set_input
  "filter the rows which have to be updated"
  where: StockCategories_bool_exp!
}

input Stocks_aggregate_bool_exp {
  count: Stocks_aggregate_bool_exp_count
}

input Stocks_aggregate_bool_exp_count {
  arguments: [Stocks_select_column!]
  distinct: Boolean
  filter: Stocks_bool_exp
  predicate: Int_comparison_exp!
}

"order by aggregate values of table \"Stocks\""
input Stocks_aggregate_order_by {
  avg: Stocks_avg_order_by
  count: order_by
  max: Stocks_max_order_by
  min: Stocks_min_order_by
  stddev: Stocks_stddev_order_by
  stddev_pop: Stocks_stddev_pop_order_by
  stddev_samp: Stocks_stddev_samp_order_by
  sum: Stocks_sum_order_by
  var_pop: Stocks_var_pop_order_by
  var_samp: Stocks_var_samp_order_by
  variance: Stocks_variance_order_by
}

"input type for inserting array relation for remote table \"Stocks\""
input Stocks_arr_rel_insert_input {
  data: [Stocks_insert_input!]!
  "upsert condition"
  on_conflict: Stocks_on_conflict
}

"order by avg() on columns of table \"Stocks\""
input Stocks_avg_order_by {
  pricePerUnit: order_by
}

"Boolean expression to filter rows from the table \"Stocks\". All fields are combined with a logical 'AND'."
input Stocks_bool_exp {
  Category: StockCategories_bool_exp
  Organization: Organizations_bool_exp
  _and: [Stocks_bool_exp!]
  _not: Stocks_bool_exp
  _or: [Stocks_bool_exp!]
  categoryId: uuid_comparison_exp
  createdAt: timestamp_comparison_exp
  id: uuid_comparison_exp
  name: String_comparison_exp
  organizationId: uuid_comparison_exp
  pricePerUnit: numeric_comparison_exp
  unit: String_comparison_exp
  updatedAt: timestamptz_comparison_exp
}

"input type for incrementing numeric columns in table \"Stocks\""
input Stocks_inc_input {
  pricePerUnit: numeric
}

"input type for inserting data into table \"Stocks\""
input Stocks_insert_input {
  Category: StockCategories_obj_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  pricePerUnit: numeric
  unit: String
  updatedAt: timestamptz
}

"order by max() on columns of table \"Stocks\""
input Stocks_max_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  pricePerUnit: order_by
  unit: order_by
  updatedAt: order_by
}

"order by min() on columns of table \"Stocks\""
input Stocks_min_order_by {
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  pricePerUnit: order_by
  unit: order_by
  updatedAt: order_by
}

"on_conflict condition type for table \"Stocks\""
input Stocks_on_conflict {
  constraint: Stocks_constraint!
  update_columns: [Stocks_update_column!]! = []
  where: Stocks_bool_exp
}

"Ordering options when selecting data from \"Stocks\"."
input Stocks_order_by {
  Category: StockCategories_order_by
  Organization: Organizations_order_by
  categoryId: order_by
  createdAt: order_by
  id: order_by
  name: order_by
  organizationId: order_by
  pricePerUnit: order_by
  unit: order_by
  updatedAt: order_by
}

"primary key columns input for table: Stocks"
input Stocks_pk_columns_input {
  id: uuid!
}

"input type for updating data in table \"Stocks\""
input Stocks_set_input {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  pricePerUnit: numeric
  unit: String
  updatedAt: timestamptz
}

"order by stddev() on columns of table \"Stocks\""
input Stocks_stddev_order_by {
  pricePerUnit: order_by
}

"order by stddev_pop() on columns of table \"Stocks\""
input Stocks_stddev_pop_order_by {
  pricePerUnit: order_by
}

"order by stddev_samp() on columns of table \"Stocks\""
input Stocks_stddev_samp_order_by {
  pricePerUnit: order_by
}

"Streaming cursor of the table \"Stocks\""
input Stocks_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Stocks_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Stocks_stream_cursor_value_input {
  categoryId: uuid
  createdAt: timestamp
  id: uuid
  name: String
  organizationId: uuid
  pricePerUnit: numeric
  unit: String
  updatedAt: timestamptz
}

"order by sum() on columns of table \"Stocks\""
input Stocks_sum_order_by {
  pricePerUnit: order_by
}

input Stocks_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: Stocks_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: Stocks_set_input
  "filter the rows which have to be updated"
  where: Stocks_bool_exp!
}

"order by var_pop() on columns of table \"Stocks\""
input Stocks_var_pop_order_by {
  pricePerUnit: order_by
}

"order by var_samp() on columns of table \"Stocks\""
input Stocks_var_samp_order_by {
  pricePerUnit: order_by
}

"order by variance() on columns of table \"Stocks\""
input Stocks_variance_order_by {
  pricePerUnit: order_by
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String
  "does the column match the given case-insensitive pattern"
  _ilike: String
  _in: [String!]
  "does the column match the given POSIX regular expression, case insensitive"
  _iregex: String
  _is_null: Boolean
  "does the column match the given pattern"
  _like: String
  _lt: String
  _lte: String
  _neq: String
  "does the column NOT match the given case-insensitive pattern"
  _nilike: String
  _nin: [String!]
  "does the column NOT match the given POSIX regular expression, case insensitive"
  _niregex: String
  "does the column NOT match the given pattern"
  _nlike: String
  "does the column NOT match the given POSIX regular expression, case sensitive"
  _nregex: String
  "does the column NOT match the given SQL regular expression"
  _nsimilar: String
  "does the column match the given POSIX regular expression, case sensitive"
  _regex: String
  "does the column match the given SQL regular expression"
  _similar: String
}

"Boolean expression to filter rows from the table \"Units\". All fields are combined with a logical 'AND'."
input Units_bool_exp {
  InvoiceSections: InvoiceSections_bool_exp
  InvoiceSections_aggregate: InvoiceSections_aggregate_bool_exp
  Organization: Organizations_bool_exp
  QuotationSections: QuotationSections_bool_exp
  QuotationSections_aggregate: QuotationSections_aggregate_bool_exp
  _and: [Units_bool_exp!]
  _not: Units_bool_exp
  _or: [Units_bool_exp!]
  organizationId: uuid_comparison_exp
  value: String_comparison_exp
}

"input type for inserting data into table \"Units\""
input Units_insert_input {
  InvoiceSections: InvoiceSections_arr_rel_insert_input
  Organization: Organizations_obj_rel_insert_input
  QuotationSections: QuotationSections_arr_rel_insert_input
  organizationId: uuid
  value: String
}

"input type for inserting object relation for remote table \"Units\""
input Units_obj_rel_insert_input {
  data: Units_insert_input!
  "upsert condition"
  on_conflict: Units_on_conflict
}

"on_conflict condition type for table \"Units\""
input Units_on_conflict {
  constraint: Units_constraint!
  update_columns: [Units_update_column!]! = []
  where: Units_bool_exp
}

"Ordering options when selecting data from \"Units\"."
input Units_order_by {
  InvoiceSections_aggregate: InvoiceSections_aggregate_order_by
  Organization: Organizations_order_by
  QuotationSections_aggregate: QuotationSections_aggregate_order_by
  organizationId: order_by
  value: order_by
}

"primary key columns input for table: Units"
input Units_pk_columns_input {
  value: String!
}

"input type for updating data in table \"Units\""
input Units_set_input {
  organizationId: uuid
  value: String
}

"Streaming cursor of the table \"Units\""
input Units_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: Units_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input Units_stream_cursor_value_input {
  organizationId: uuid
  value: String
}

input Units_updates {
  "sets the columns of the filtered rows to the given values"
  _set: Units_set_input
  "filter the rows which have to be updated"
  where: Units_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_email_templates\". All fields are combined with a logical 'AND'."
input authorizer_email_templates_bool_exp {
  _and: [authorizer_email_templates_bool_exp!]
  _not: authorizer_email_templates_bool_exp
  _or: [authorizer_email_templates_bool_exp!]
  created_at: bigint_comparison_exp
  design: String_comparison_exp
  event_name: String_comparison_exp
  id: bpchar_comparison_exp
  key: String_comparison_exp
  subject: String_comparison_exp
  template: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_email_templates\""
input authorizer_email_templates_inc_input {
  created_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_email_templates\""
input authorizer_email_templates_insert_input {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar
  key: String
  subject: String
  template: String
  updated_at: bigint
}

"on_conflict condition type for table \"authorizer_email_templates\""
input authorizer_email_templates_on_conflict {
  constraint: authorizer_email_templates_constraint!
  update_columns: [authorizer_email_templates_update_column!]! = []
  where: authorizer_email_templates_bool_exp
}

"Ordering options when selecting data from \"authorizer_email_templates\"."
input authorizer_email_templates_order_by {
  created_at: order_by
  design: order_by
  event_name: order_by
  id: order_by
  key: order_by
  subject: order_by
  template: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_email_templates"
input authorizer_email_templates_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_email_templates\""
input authorizer_email_templates_set_input {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar
  key: String
  subject: String
  template: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_email_templates\""
input authorizer_email_templates_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_email_templates_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_email_templates_stream_cursor_value_input {
  created_at: bigint
  design: String
  event_name: String
  id: bpchar
  key: String
  subject: String
  template: String
  updated_at: bigint
}

input authorizer_email_templates_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_email_templates_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_email_templates_set_input
  "filter the rows which have to be updated"
  where: authorizer_email_templates_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_envs\". All fields are combined with a logical 'AND'."
input authorizer_envs_bool_exp {
  _and: [authorizer_envs_bool_exp!]
  _not: authorizer_envs_bool_exp
  _or: [authorizer_envs_bool_exp!]
  created_at: bigint_comparison_exp
  encryption_key: String_comparison_exp
  env_data: String_comparison_exp
  hash: String_comparison_exp
  id: bpchar_comparison_exp
  key: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_envs\""
input authorizer_envs_inc_input {
  created_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_envs\""
input authorizer_envs_insert_input {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar
  key: String
  updated_at: bigint
}

"on_conflict condition type for table \"authorizer_envs\""
input authorizer_envs_on_conflict {
  constraint: authorizer_envs_constraint!
  update_columns: [authorizer_envs_update_column!]! = []
  where: authorizer_envs_bool_exp
}

"Ordering options when selecting data from \"authorizer_envs\"."
input authorizer_envs_order_by {
  created_at: order_by
  encryption_key: order_by
  env_data: order_by
  hash: order_by
  id: order_by
  key: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_envs"
input authorizer_envs_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_envs\""
input authorizer_envs_set_input {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar
  key: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_envs\""
input authorizer_envs_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_envs_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_envs_stream_cursor_value_input {
  created_at: bigint
  encryption_key: String
  env_data: String
  hash: String
  id: bpchar
  key: String
  updated_at: bigint
}

input authorizer_envs_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_envs_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_envs_set_input
  "filter the rows which have to be updated"
  where: authorizer_envs_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_otps\". All fields are combined with a logical 'AND'."
input authorizer_otps_bool_exp {
  _and: [authorizer_otps_bool_exp!]
  _not: authorizer_otps_bool_exp
  _or: [authorizer_otps_bool_exp!]
  created_at: bigint_comparison_exp
  email: String_comparison_exp
  expires_at: bigint_comparison_exp
  id: bpchar_comparison_exp
  key: String_comparison_exp
  otp: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_otps\""
input authorizer_otps_inc_input {
  created_at: bigint
  expires_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_otps\""
input authorizer_otps_insert_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  key: String
  otp: String
  updated_at: bigint
}

"on_conflict condition type for table \"authorizer_otps\""
input authorizer_otps_on_conflict {
  constraint: authorizer_otps_constraint!
  update_columns: [authorizer_otps_update_column!]! = []
  where: authorizer_otps_bool_exp
}

"Ordering options when selecting data from \"authorizer_otps\"."
input authorizer_otps_order_by {
  created_at: order_by
  email: order_by
  expires_at: order_by
  id: order_by
  key: order_by
  otp: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_otps"
input authorizer_otps_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_otps\""
input authorizer_otps_set_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  key: String
  otp: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_otps\""
input authorizer_otps_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_otps_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_otps_stream_cursor_value_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  key: String
  otp: String
  updated_at: bigint
}

input authorizer_otps_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_otps_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_otps_set_input
  "filter the rows which have to be updated"
  where: authorizer_otps_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_sessions\". All fields are combined with a logical 'AND'."
input authorizer_sessions_bool_exp {
  _and: [authorizer_sessions_bool_exp!]
  _not: authorizer_sessions_bool_exp
  _or: [authorizer_sessions_bool_exp!]
  created_at: bigint_comparison_exp
  id: bpchar_comparison_exp
  ip: String_comparison_exp
  key: String_comparison_exp
  updated_at: bigint_comparison_exp
  user_agent: String_comparison_exp
  user_id: bpchar_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_sessions\""
input authorizer_sessions_inc_input {
  created_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_sessions\""
input authorizer_sessions_insert_input {
  created_at: bigint
  id: bpchar
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

"on_conflict condition type for table \"authorizer_sessions\""
input authorizer_sessions_on_conflict {
  constraint: authorizer_sessions_constraint!
  update_columns: [authorizer_sessions_update_column!]! = []
  where: authorizer_sessions_bool_exp
}

"Ordering options when selecting data from \"authorizer_sessions\"."
input authorizer_sessions_order_by {
  created_at: order_by
  id: order_by
  ip: order_by
  key: order_by
  updated_at: order_by
  user_agent: order_by
  user_id: order_by
}

"primary key columns input for table: authorizer_sessions"
input authorizer_sessions_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_sessions\""
input authorizer_sessions_set_input {
  created_at: bigint
  id: bpchar
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

"Streaming cursor of the table \"authorizer_sessions\""
input authorizer_sessions_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_sessions_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_sessions_stream_cursor_value_input {
  created_at: bigint
  id: bpchar
  ip: String
  key: String
  updated_at: bigint
  user_agent: String
  user_id: bpchar
}

input authorizer_sessions_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_sessions_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_sessions_set_input
  "filter the rows which have to be updated"
  where: authorizer_sessions_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_users\". All fields are combined with a logical 'AND'."
input authorizer_users_bool_exp {
  Organizations: Organizations_bool_exp
  Organizations_aggregate: Organizations_aggregate_bool_exp
  _and: [authorizer_users_bool_exp!]
  _not: authorizer_users_bool_exp
  _or: [authorizer_users_bool_exp!]
  birthdate: String_comparison_exp
  created_at: bigint_comparison_exp
  email: String_comparison_exp
  email_verified_at: bigint_comparison_exp
  family_name: String_comparison_exp
  gender: String_comparison_exp
  given_name: String_comparison_exp
  id: bpchar_comparison_exp
  is_multi_factor_auth_enabled: Boolean_comparison_exp
  key: String_comparison_exp
  middle_name: String_comparison_exp
  nickname: String_comparison_exp
  password: String_comparison_exp
  phone_number: String_comparison_exp
  phone_number_verified_at: bigint_comparison_exp
  picture: String_comparison_exp
  revoked_timestamp: bigint_comparison_exp
  roles: String_comparison_exp
  signup_methods: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_users\""
input authorizer_users_inc_input {
  created_at: bigint
  email_verified_at: bigint
  phone_number_verified_at: bigint
  revoked_timestamp: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_users\""
input authorizer_users_insert_input {
  Organizations: Organizations_arr_rel_insert_input
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar
  is_multi_factor_auth_enabled: Boolean
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

"input type for inserting object relation for remote table \"authorizer_users\""
input authorizer_users_obj_rel_insert_input {
  data: authorizer_users_insert_input!
  "upsert condition"
  on_conflict: authorizer_users_on_conflict
}

"on_conflict condition type for table \"authorizer_users\""
input authorizer_users_on_conflict {
  constraint: authorizer_users_constraint!
  update_columns: [authorizer_users_update_column!]! = []
  where: authorizer_users_bool_exp
}

"Ordering options when selecting data from \"authorizer_users\"."
input authorizer_users_order_by {
  Organizations_aggregate: Organizations_aggregate_order_by
  birthdate: order_by
  created_at: order_by
  email: order_by
  email_verified_at: order_by
  family_name: order_by
  gender: order_by
  given_name: order_by
  id: order_by
  is_multi_factor_auth_enabled: order_by
  key: order_by
  middle_name: order_by
  nickname: order_by
  password: order_by
  phone_number: order_by
  phone_number_verified_at: order_by
  picture: order_by
  revoked_timestamp: order_by
  roles: order_by
  signup_methods: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_users"
input authorizer_users_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_users\""
input authorizer_users_set_input {
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar
  is_multi_factor_auth_enabled: Boolean
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_users\""
input authorizer_users_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_users_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_users_stream_cursor_value_input {
  birthdate: String
  created_at: bigint
  email: String
  email_verified_at: bigint
  family_name: String
  gender: String
  given_name: String
  id: bpchar
  is_multi_factor_auth_enabled: Boolean
  key: String
  middle_name: String
  nickname: String
  password: String
  phone_number: String
  phone_number_verified_at: bigint
  picture: String
  revoked_timestamp: bigint
  roles: String
  signup_methods: String
  updated_at: bigint
}

input authorizer_users_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_users_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_users_set_input
  "filter the rows which have to be updated"
  where: authorizer_users_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_verification_requests\". All fields are combined with a logical 'AND'."
input authorizer_verification_requests_bool_exp {
  _and: [authorizer_verification_requests_bool_exp!]
  _not: authorizer_verification_requests_bool_exp
  _or: [authorizer_verification_requests_bool_exp!]
  created_at: bigint_comparison_exp
  email: String_comparison_exp
  expires_at: bigint_comparison_exp
  id: bpchar_comparison_exp
  identifier: String_comparison_exp
  key: String_comparison_exp
  nonce: String_comparison_exp
  redirect_uri: String_comparison_exp
  token: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_verification_requests\""
input authorizer_verification_requests_inc_input {
  created_at: bigint
  expires_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_verification_requests\""
input authorizer_verification_requests_insert_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

"on_conflict condition type for table \"authorizer_verification_requests\""
input authorizer_verification_requests_on_conflict {
  constraint: authorizer_verification_requests_constraint!
  update_columns: [authorizer_verification_requests_update_column!]! = []
  where: authorizer_verification_requests_bool_exp
}

"Ordering options when selecting data from \"authorizer_verification_requests\"."
input authorizer_verification_requests_order_by {
  created_at: order_by
  email: order_by
  expires_at: order_by
  id: order_by
  identifier: order_by
  key: order_by
  nonce: order_by
  redirect_uri: order_by
  token: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_verification_requests"
input authorizer_verification_requests_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_verification_requests\""
input authorizer_verification_requests_set_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_verification_requests\""
input authorizer_verification_requests_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_verification_requests_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_verification_requests_stream_cursor_value_input {
  created_at: bigint
  email: String
  expires_at: bigint
  id: bpchar
  identifier: String
  key: String
  nonce: String
  redirect_uri: String
  token: String
  updated_at: bigint
}

input authorizer_verification_requests_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_verification_requests_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_verification_requests_set_input
  "filter the rows which have to be updated"
  where: authorizer_verification_requests_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_webhook_logs\". All fields are combined with a logical 'AND'."
input authorizer_webhook_logs_bool_exp {
  _and: [authorizer_webhook_logs_bool_exp!]
  _not: authorizer_webhook_logs_bool_exp
  _or: [authorizer_webhook_logs_bool_exp!]
  created_at: bigint_comparison_exp
  http_status: bigint_comparison_exp
  id: bpchar_comparison_exp
  key: String_comparison_exp
  request: String_comparison_exp
  response: String_comparison_exp
  updated_at: bigint_comparison_exp
  webhook_id: bpchar_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_webhook_logs\""
input authorizer_webhook_logs_inc_input {
  created_at: bigint
  http_status: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_webhook_logs\""
input authorizer_webhook_logs_insert_input {
  created_at: bigint
  http_status: bigint
  id: bpchar
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

"on_conflict condition type for table \"authorizer_webhook_logs\""
input authorizer_webhook_logs_on_conflict {
  constraint: authorizer_webhook_logs_constraint!
  update_columns: [authorizer_webhook_logs_update_column!]! = []
  where: authorizer_webhook_logs_bool_exp
}

"Ordering options when selecting data from \"authorizer_webhook_logs\"."
input authorizer_webhook_logs_order_by {
  created_at: order_by
  http_status: order_by
  id: order_by
  key: order_by
  request: order_by
  response: order_by
  updated_at: order_by
  webhook_id: order_by
}

"primary key columns input for table: authorizer_webhook_logs"
input authorizer_webhook_logs_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_webhook_logs\""
input authorizer_webhook_logs_set_input {
  created_at: bigint
  http_status: bigint
  id: bpchar
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

"Streaming cursor of the table \"authorizer_webhook_logs\""
input authorizer_webhook_logs_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_webhook_logs_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_webhook_logs_stream_cursor_value_input {
  created_at: bigint
  http_status: bigint
  id: bpchar
  key: String
  request: String
  response: String
  updated_at: bigint
  webhook_id: bpchar
}

input authorizer_webhook_logs_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_webhook_logs_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_webhook_logs_set_input
  "filter the rows which have to be updated"
  where: authorizer_webhook_logs_bool_exp!
}

"Boolean expression to filter rows from the table \"authorizer_webhooks\". All fields are combined with a logical 'AND'."
input authorizer_webhooks_bool_exp {
  _and: [authorizer_webhooks_bool_exp!]
  _not: authorizer_webhooks_bool_exp
  _or: [authorizer_webhooks_bool_exp!]
  created_at: bigint_comparison_exp
  enabled: Boolean_comparison_exp
  end_point: String_comparison_exp
  event_name: String_comparison_exp
  headers: String_comparison_exp
  id: bpchar_comparison_exp
  key: String_comparison_exp
  updated_at: bigint_comparison_exp
}

"input type for incrementing numeric columns in table \"authorizer_webhooks\""
input authorizer_webhooks_inc_input {
  created_at: bigint
  updated_at: bigint
}

"input type for inserting data into table \"authorizer_webhooks\""
input authorizer_webhooks_insert_input {
  created_at: bigint
  enabled: Boolean
  end_point: String
  event_name: String
  headers: String
  id: bpchar
  key: String
  updated_at: bigint
}

"on_conflict condition type for table \"authorizer_webhooks\""
input authorizer_webhooks_on_conflict {
  constraint: authorizer_webhooks_constraint!
  update_columns: [authorizer_webhooks_update_column!]! = []
  where: authorizer_webhooks_bool_exp
}

"Ordering options when selecting data from \"authorizer_webhooks\"."
input authorizer_webhooks_order_by {
  created_at: order_by
  enabled: order_by
  end_point: order_by
  event_name: order_by
  headers: order_by
  id: order_by
  key: order_by
  updated_at: order_by
}

"primary key columns input for table: authorizer_webhooks"
input authorizer_webhooks_pk_columns_input {
  id: bpchar!
}

"input type for updating data in table \"authorizer_webhooks\""
input authorizer_webhooks_set_input {
  created_at: bigint
  enabled: Boolean
  end_point: String
  event_name: String
  headers: String
  id: bpchar
  key: String
  updated_at: bigint
}

"Streaming cursor of the table \"authorizer_webhooks\""
input authorizer_webhooks_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: authorizer_webhooks_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input authorizer_webhooks_stream_cursor_value_input {
  created_at: bigint
  enabled: Boolean
  end_point: String
  event_name: String
  headers: String
  id: bpchar
  key: String
  updated_at: bigint
}

input authorizer_webhooks_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: authorizer_webhooks_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: authorizer_webhooks_set_input
  "filter the rows which have to be updated"
  where: authorizer_webhooks_bool_exp!
}

"Boolean expression to compare columns of type \"bigint\". All fields are combined with logical 'AND'."
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

"Boolean expression to compare columns of type \"bpchar\". All fields are combined with logical 'AND'."
input bpchar_comparison_exp {
  _eq: bpchar
  _gt: bpchar
  _gte: bpchar
  "does the column match the given case-insensitive pattern"
  _ilike: bpchar
  _in: [bpchar!]
  "does the column match the given POSIX regular expression, case insensitive"
  _iregex: bpchar
  _is_null: Boolean
  "does the column match the given pattern"
  _like: bpchar
  _lt: bpchar
  _lte: bpchar
  _neq: bpchar
  "does the column NOT match the given case-insensitive pattern"
  _nilike: bpchar
  _nin: [bpchar!]
  "does the column NOT match the given POSIX regular expression, case insensitive"
  _niregex: bpchar
  "does the column NOT match the given pattern"
  _nlike: bpchar
  "does the column NOT match the given POSIX regular expression, case sensitive"
  _nregex: bpchar
  "does the column NOT match the given SQL regular expression"
  _nsimilar: bpchar
  "does the column match the given POSIX regular expression, case sensitive"
  _regex: bpchar
  "does the column match the given SQL regular expression"
  _similar: bpchar
}

"Boolean expression to compare columns of type \"date\". All fields are combined with logical 'AND'."
input date_comparison_exp {
  _eq: date
  _gt: date
  _gte: date
  _in: [date!]
  _is_null: Boolean
  _lt: date
  _lte: date
  _neq: date
  _nin: [date!]
}

"Boolean expression to compare columns of type \"numeric\". All fields are combined with logical 'AND'."
input numeric_comparison_exp {
  _eq: numeric
  _gt: numeric
  _gte: numeric
  _in: [numeric!]
  _is_null: Boolean
  _lt: numeric
  _lte: numeric
  _neq: numeric
  _nin: [numeric!]
}

"Boolean expression to compare columns of type \"timestamp\". All fields are combined with logical 'AND'."
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

"Boolean expression to compare columns of type \"uuid\". All fields are combined with logical 'AND'."
input uuid_comparison_exp {
  _eq: uuid
  _gt: uuid
  _gte: uuid
  _in: [uuid!]
  _is_null: Boolean
  _lt: uuid
  _lte: uuid
  _neq: uuid
  _nin: [uuid!]
}
